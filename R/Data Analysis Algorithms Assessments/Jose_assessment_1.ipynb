{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT5201: Assessment 1\n",
    "## The Elements of Machine Learning\n",
    "\n",
    "### Objectives\n",
    "This assignment consists of three parts (A,B,C) that assess your understanding of model complexity, model selection, uncertainty in prediction with bootstrapping, and probabilistic machine learning. The total marks of this assessment is 100, and will contribute to the 20% of your final score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R version 3.3.2 (2016-10-31)\n",
       "Platform: x86_64-w64-mingw32/x64 (64-bit)\n",
       "Running under: Windows 10 x64 (build 15063)\n",
       "\n",
       "locale:\n",
       "[1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252   \n",
       "[3] LC_MONETARY=English_Australia.1252 LC_NUMERIC=C                      \n",
       "[5] LC_TIME=English_Australia.1252    \n",
       "\n",
       "attached base packages:\n",
       "[1] stats     graphics  grDevices utils     datasets  methods   base     \n",
       "\n",
       "loaded via a namespace (and not attached):\n",
       " [1] R6_2.2.2            magrittr_1.5        IRdisplay_0.4.4    \n",
       " [4] pbdZMQ_0.2-6        tools_3.3.2         crayon_1.3.2       \n",
       " [7] uuid_0.1-2          stringi_1.1.5       IRkernel_0.8.7.9000\n",
       "[10] jsonlite_1.5        stringr_1.2.0       digest_0.6.12      \n",
       "[13] repr_0.12.0         evaluate_0.10.1    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# information about the R kernel and machine used\n",
    "sessionInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'ggplot2' was built under R version 3.3.3\"Warning message:\n",
      "\"package 'corrplot' was built under R version 3.3.3\""
     ]
    }
   ],
   "source": [
    "# declare the libraries we will be using\n",
    "library(reshape2)\n",
    "library(ggplot2)\n",
    "library(corrplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A.  Model Complexity and Model Selection\n",
    "In this part, you study the effect of model complexity on the training and testing errors.  You also demonstrate your programming skills by developing a regression algorithm and a cross-validation technique that will be used to select the models with the most effective complexity.\n",
    "\n",
    "__Background__. A KNN regressor is similar to a KNN classifier (covered in Activity 1.1) in that it finds the K nearest neighbors and estimates the value of the given test point based on the values of its neighbours. The main difference between KNN regression and KNN classification is that KNN classifier returns the label that has the majority vote in the neighborhood, whilst KNN regressor returns the average of the neighborsâ€™ values. \n",
    "\n",
    "#### Question 1 [KNN Regressor, 20 Marks] \n",
    "Q1-1) Implement the KNN regressor function:\n",
    "                                     knn(train.data, train.label, test.data, K=3) \n",
    "which takes the training data and their labels (continuous values), the test set, and the size of the neighborhood (K). It should return the regressed values for the test data points. When choosing the neighbors, you can use the Euclidean distance function to measure the distance between a pair of data points. \n",
    "\n",
    "__Hint__: You are allowed to use KNN classifier code from Activity 1 of Module 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1-1** \n",
    "\n",
    "For data analysis, the first and foremost step is exploring what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Training Data\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>x1</th><th scope=col>y</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1960.0</td><td>0.71  </td></tr>\n",
       "\t<tr><td>1960.5</td><td>0.85  </td></tr>\n",
       "\t<tr><td>1961.0</td><td>0.61  </td></tr>\n",
       "\t<tr><td>1961.5</td><td>0.92  </td></tr>\n",
       "\t<tr><td>1962.0</td><td>0.72  </td></tr>\n",
       "\t<tr><td>1962.5</td><td>0.92  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " x1 & y\\\\\n",
       "\\hline\n",
       "\t 1960.0 & 0.71  \\\\\n",
       "\t 1960.5 & 0.85  \\\\\n",
       "\t 1961.0 & 0.61  \\\\\n",
       "\t 1961.5 & 0.92  \\\\\n",
       "\t 1962.0 & 0.72  \\\\\n",
       "\t 1962.5 & 0.92  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "x1 | y | \n",
       "|---|---|---|---|---|---|\n",
       "| 1960.0 | 0.71   | \n",
       "| 1960.5 | 0.85   | \n",
       "| 1961.0 | 0.61   | \n",
       "| 1961.5 | 0.92   | \n",
       "| 1962.0 | 0.72   | \n",
       "| 1962.5 | 0.92   | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  x1     y   \n",
       "1 1960.0 0.71\n",
       "2 1960.5 0.85\n",
       "3 1961.0 0.61\n",
       "4 1961.5 0.92\n",
       "5 1962.0 0.72\n",
       "6 1962.5 0.92"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Testing Data\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>x1</th><th scope=col>y</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1960.25</td><td>0.63   </td></tr>\n",
       "\t<tr><td>1960.75</td><td>0.44   </td></tr>\n",
       "\t<tr><td>1961.25</td><td>0.69   </td></tr>\n",
       "\t<tr><td>1961.75</td><td>0.55   </td></tr>\n",
       "\t<tr><td>1962.25</td><td>0.77   </td></tr>\n",
       "\t<tr><td>1962.75</td><td>0.60   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " x1 & y\\\\\n",
       "\\hline\n",
       "\t 1960.25 & 0.63   \\\\\n",
       "\t 1960.75 & 0.44   \\\\\n",
       "\t 1961.25 & 0.69   \\\\\n",
       "\t 1961.75 & 0.55   \\\\\n",
       "\t 1962.25 & 0.77   \\\\\n",
       "\t 1962.75 & 0.60   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "x1 | y | \n",
       "|---|---|---|---|---|---|\n",
       "| 1960.25 | 0.63    | \n",
       "| 1960.75 | 0.44    | \n",
       "| 1961.25 | 0.69    | \n",
       "| 1961.75 | 0.55    | \n",
       "| 1962.25 | 0.77    | \n",
       "| 1962.75 | 0.60    | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  x1      y   \n",
       "1 1960.25 0.63\n",
       "2 1960.75 0.44\n",
       "3 1961.25 0.69\n",
       "4 1961.75 0.55\n",
       "5 1962.25 0.77\n",
       "6 1962.75 0.60"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read the train and test data\n",
    "trainA.file <- read.csv(\"Task1A_train.csv\")\n",
    "testA.file <- read.csv(\"Task1A_test.csv\")\n",
    "\n",
    "print(\"Training Data\")\n",
    "head(trainA.file)\n",
    "print(\"Testing Data\")\n",
    "head(testA.file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In here we can see both the input $x$ and target variable $t$. Machine learning always starts with these two types of variables, where the goal is to use all input variables to predict or infer target variables: $t = f(x)$. We also have two types of data,  **training** and **testing** data. The former is used to train the model we'll be creating, and the latter to test the effectiveness of that model.\n",
    "\n",
    "Based on the results above we can see that we only have 1 **input variable** corresponding to another 1 **target variable**. Now we can divide them into both **data** (the *input variable*) and **value** (*the target variable*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the first column of the data frames and rename them as \"data\"\n",
    "trainA.dt <- as.data.frame(trainA.file[,1]) \n",
    "colnames(trainA.dt) <- c(\"data\")\n",
    "\n",
    "testA.dt <- as.data.frame(testA.file[,1])\n",
    "colnames(testA.dt) <- c(\"data\")\n",
    "\n",
    "# get the last column of the data frame\n",
    "trainA.vl <- trainA.file[,-1]\n",
    "testA.vl <- testA.file[,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"number of training obs:  42\"\n",
      "[1] \"number of testing obs:  42\"\n"
     ]
    }
   ],
   "source": [
    "# explore the data - how many rows does the training and testing have?\n",
    "print(paste(\"number of training obs: \", nrow(trainA.dt)))\n",
    "print(paste(\"number of testing obs: \", nrow(testA.dt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define the KNN Regressor. Activity 1 implemented a **KNN Classifier**, wherein the target variable is a *label* or a discrete value (setosa, virginica, versicolor). In the assessment's case, since the target is a *continuous* variable a **KNN Regressor** is required.\n",
    "\n",
    "**KNN Regressor** works similarly to a **KNN Classifier** in detecting the K nearest neighbours. The main difference is the prediction made by the classifier came from getting the *mode* (or the most frequent value within the neighbours) while the regressor gets the *mean* (the average of the values of the neighbours)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameters:\n",
    "# train.data - a dataframe of training data (input variables)\n",
    "# train.value - a dataframe of training values (target variable)\n",
    "# test.data - a dataframe of testing data (input variables)\n",
    "# K - the number of nearest neighbours\n",
    "# distance - should be one of euclidean, maximum, manhattan, canberra, binary or minkowski\n",
    "# KNN function\n",
    "knn <- function(train.data, train.value, test.data, K=3, distance = 'euclidean'){\n",
    "    ## count number of train samples\n",
    "    train.len <- nrow(train.data)\n",
    "    \n",
    "    ## count number of test samples\n",
    "    test.len <- nrow(test.data)\n",
    "    \n",
    "    ## calculate distances between samples\n",
    "    dist <- as.matrix(dist(rbind(test.data, train.data), method = distance))[1:test.len, (test.len + 1):(test.len + train.len)]\n",
    "    \n",
    "    test.value <- c()\n",
    "    \n",
    "    ## for each test sample...\n",
    "    for (i in 1:test.len){\n",
    "        ### ...find its K nearest neighbours from training sampels...\n",
    "        nn <- as.data.frame(sort(dist[i,], index.return = TRUE))[1:K, 2]\n",
    "        \n",
    "        ###...and calculate the predicted labels according to the mean of the neighbours\n",
    "        test.value[i]<- (round(mean(train.value[nn]), 2))\n",
    "    }\n",
    "    \n",
    "    ## return the class labels as output\n",
    "    return (test.value)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function defines the **root mean squared-error (RMSE)**. The **root mean squared-error** is a function that determines the difference between the model's predicted value $\\widehat{Y_i}$, and the actual value $Y_i$ of the target variable. The difference is squared and the square root of the mean was taken to *normalise* the values of the errors.\n",
    "\n",
    "$$\n",
    "RMSE = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n} (\\widehat{Y_i}-Y_i)^2}\n",
    "$$\n",
    "\n",
    "In Machine Learning, the goal is to minimise the error (or the difference) between the model's values and the corresponding target values of the test set, after the model has been trained from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function to get the root mean squared-error (RMSE)\n",
    "# parameters:\n",
    "# predicted.values - a vector of predicted values\n",
    "# actual.values - a vector of actual.values\n",
    "get.rmse <- function(predicted.values, actual.values){\n",
    "    p.length <- length(predicted.values)\n",
    "    a.length <- length(actual.values)\n",
    "    \n",
    "    if (p.length == a.length){\n",
    "        # square the errors (difference of predicted and actual)\n",
    "        squared.errors <- (predicted.values - actual.values)^2\n",
    "        \n",
    "        # get the mean\n",
    "        mean.squared.errors <- mean(squared.errors)\n",
    "        \n",
    "        # return the resulting square root\n",
    "        return (sqrt(mean.squared.errors))\n",
    "    }\n",
    "    else{\n",
    "        stop(\"Both numeric vectors must be equal!\")\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "2.82842712474619"
      ],
      "text/latex": [
       "2.82842712474619"
      ],
      "text/markdown": [
       "2.82842712474619"
      ],
      "text/plain": [
       "[1] 2.828427"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test if the get.rmse is working as intended\n",
    "a <- c(2,3,4,5)\n",
    "b <- c(6,7,4,5)\n",
    "\n",
    "get.rmse(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1-2**\n",
    "\n",
    "Q1-2) Plot the training and the testing errors versus 1/K for K=1,..,20 in one plot, using the Task1A_train.csv and Task1A_test.csv datasets provided for this assignment. \n",
    "\n",
    "The following code just gets the RMSE of the model made from implementing the KNN algorithm (code based from Acitivity 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "miss <- data.frame('K' = 1:20, 'train' = rep(0,20), 'test' = rep(0,20))\n",
    "\n",
    "# for each K\n",
    "for (k in 1:20){\n",
    "    # get the error when the training and the testing data both came from the \"training\" set\n",
    "    miss[k, 'train'] <- round(get.rmse(knn(trainA.dt, trainA.vl, trainA.dt, K=k), trainA.vl), 2)\n",
    "    \n",
    "    # get the error when the testing data came from the \"testing\" set\n",
    "    miss[k, 'test'] <- round(get.rmse(knn(trainA.dt, trainA.vl, testA.dt, K=k), testA.vl), 2)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to check the errors to determine the most optimal K. In this case, the most optimal K is the one with the *least* testing errors. This means that the model was able to predict a value that is *almost similar* to the actual target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>K</th><th scope=col>train</th><th scope=col>test</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 1  </td><td>0.00</td><td>1.30</td></tr>\n",
       "\t<tr><td> 2  </td><td>0.35</td><td>1.46</td></tr>\n",
       "\t<tr><td> 3  </td><td>0.31</td><td>1.30</td></tr>\n",
       "\t<tr><td> 4  </td><td>0.39</td><td>1.36</td></tr>\n",
       "\t<tr><td> 5  </td><td>0.40</td><td>1.17</td></tr>\n",
       "\t<tr><td> 6  </td><td>0.53</td><td>1.21</td></tr>\n",
       "\t<tr><td> 7  </td><td>0.66</td><td>1.04</td></tr>\n",
       "\t<tr><td> 8  </td><td>0.79</td><td>1.09</td></tr>\n",
       "\t<tr><td> 9  </td><td>0.95</td><td>0.98</td></tr>\n",
       "\t<tr><td>10  </td><td>1.08</td><td>1.02</td></tr>\n",
       "\t<tr><td>11  </td><td>1.21</td><td>0.95</td></tr>\n",
       "\t<tr><td>12  </td><td>1.32</td><td>1.05</td></tr>\n",
       "\t<tr><td>13  </td><td>1.45</td><td>1.02</td></tr>\n",
       "\t<tr><td>14  </td><td>1.55</td><td>1.13</td></tr>\n",
       "\t<tr><td>15  </td><td>1.66</td><td>1.12</td></tr>\n",
       "\t<tr><td>16  </td><td>1.74</td><td>1.24</td></tr>\n",
       "\t<tr><td>17  </td><td>1.87</td><td>1.25</td></tr>\n",
       "\t<tr><td>18  </td><td>1.94</td><td>1.36</td></tr>\n",
       "\t<tr><td>19  </td><td>2.06</td><td>1.38</td></tr>\n",
       "\t<tr><td>20  </td><td>2.15</td><td>1.51</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " K & train & test\\\\\n",
       "\\hline\n",
       "\t  1   & 0.00 & 1.30\\\\\n",
       "\t  2   & 0.35 & 1.46\\\\\n",
       "\t  3   & 0.31 & 1.30\\\\\n",
       "\t  4   & 0.39 & 1.36\\\\\n",
       "\t  5   & 0.40 & 1.17\\\\\n",
       "\t  6   & 0.53 & 1.21\\\\\n",
       "\t  7   & 0.66 & 1.04\\\\\n",
       "\t  8   & 0.79 & 1.09\\\\\n",
       "\t  9   & 0.95 & 0.98\\\\\n",
       "\t 10   & 1.08 & 1.02\\\\\n",
       "\t 11   & 1.21 & 0.95\\\\\n",
       "\t 12   & 1.32 & 1.05\\\\\n",
       "\t 13   & 1.45 & 1.02\\\\\n",
       "\t 14   & 1.55 & 1.13\\\\\n",
       "\t 15   & 1.66 & 1.12\\\\\n",
       "\t 16   & 1.74 & 1.24\\\\\n",
       "\t 17   & 1.87 & 1.25\\\\\n",
       "\t 18   & 1.94 & 1.36\\\\\n",
       "\t 19   & 2.06 & 1.38\\\\\n",
       "\t 20   & 2.15 & 1.51\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "K | train | test | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "|  1   | 0.00 | 1.30 | \n",
       "|  2   | 0.35 | 1.46 | \n",
       "|  3   | 0.31 | 1.30 | \n",
       "|  4   | 0.39 | 1.36 | \n",
       "|  5   | 0.40 | 1.17 | \n",
       "|  6   | 0.53 | 1.21 | \n",
       "|  7   | 0.66 | 1.04 | \n",
       "|  8   | 0.79 | 1.09 | \n",
       "|  9   | 0.95 | 0.98 | \n",
       "| 10   | 1.08 | 1.02 | \n",
       "| 11   | 1.21 | 0.95 | \n",
       "| 12   | 1.32 | 1.05 | \n",
       "| 13   | 1.45 | 1.02 | \n",
       "| 14   | 1.55 | 1.13 | \n",
       "| 15   | 1.66 | 1.12 | \n",
       "| 16   | 1.74 | 1.24 | \n",
       "| 17   | 1.87 | 1.25 | \n",
       "| 18   | 1.94 | 1.36 | \n",
       "| 19   | 2.06 | 1.38 | \n",
       "| 20   | 2.15 | 1.51 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   K  train test\n",
       "1   1 0.00  1.30\n",
       "2   2 0.35  1.46\n",
       "3   3 0.31  1.30\n",
       "4   4 0.39  1.36\n",
       "5   5 0.40  1.17\n",
       "6   6 0.53  1.21\n",
       "7   7 0.66  1.04\n",
       "8   8 0.79  1.09\n",
       "9   9 0.95  0.98\n",
       "10 10 1.08  1.02\n",
       "11 11 1.21  0.95\n",
       "12 12 1.32  1.05\n",
       "13 13 1.45  1.02\n",
       "14 14 1.55  1.13\n",
       "15 15 1.66  1.12\n",
       "16 16 1.74  1.24\n",
       "17 17 1.87  1.25\n",
       "18 18 1.94  1.36\n",
       "19 19 2.06  1.38\n",
       "20 20 2.15  1.51"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check the result\n",
    "miss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based from the results, the most optimal value for K is **11**.\n",
    "\n",
    "To be able to see the trend of errors, refer to the next plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAOVBMVEUAAAAAv8RNTU1oaGh8\nfHyMjIyampqnp6eysrK9vb3Hx8fQ0NDZ2dnh4eHp6enr6+vw8PD4dm3////ccKm3AAAACXBI\nWXMAABJ0AAASdAHeZh94AAAgAElEQVR4nO2dC0PaWrcAEe2xD1uV//9jD28DLiBh7exM2DP3\nfqfY2nGxkimIiIuViKRZTD2AyCNgSCIFMCSRAhiSSAEMSaQAhiRSAEMSKYAhiRTAkEQKYEgi\nBUiGtNjz/Ppx/R0//uu8sfzx69/+4r9fP5YDP+af/5Y9PmAPFh3SMmmbQiEtFsvrJ/bJqbp+\n99f9xdfBJ/GPw0f8M+zvRTMZkhQiHdLu17eXYxrX33H/xvPhZmj5PPAk/rVYbgr692ux+Dvo\nL96YSSRDoZBWfxfX76GdhfRz8ba99La+NGyE5WJ/r/DX4r/r73kTQ5JilArpcOnv+hOY5X/7\n24qvN07vPi0W//Y3YK+Lv/vfX9+mLV7299Ze1zdTL2976+ty8dy5F3f+Ef+s/97P7eX9n+x+\n6So+nhc/zj7Cmarzfsd371yT4++JXKDwLdKf7ucvnTfOQ1rt79stl3vF7927bvNafjnWp/7Z\n50Nn9yFft3/88zykE8WPrbf7Ec6G37+1fb/Du3evyeH3RC5R6nOk5fZEW9+8/PxYfazP7n9n\nb5zdtVsHsLm5eNueudu/uLn5+PuyOW9/rm9hNv992b7n8m318WN7ece/ze3E78OnR+uP8Xvd\nyPIspFPFy8fZRzgb/vDW9v2O734y/Ev+MUJ5aIo9arc91V/3/27/t/n15I3zkN62f7jJafsn\nr4vtmfqxuQP1vLu8/f3dLcJH92//2z1s9+PPzv1r88vvs5BOFW+rs4/wbfjO+x3f/WT4t9ya\n5OEp9XWk7fm8PoF3jwT8WzyfvXEe0uZO3eYe2P5Pnk8fh/775+fL/uw+/oUvPrZ/uk13ecjj\n/HOkb4qzj9AdfhF8qMvDiwSUuGv3sTzcXzqecZ0T++yNw29sbozeNg+87c/izin9a3nh7O7y\n9rK5+3b4g/OQIkUQ0rer8v0jfhteJKDI50hvh/s+A0L6s77P9Lp7HGJ1+se/1jc2r7//xSF9\nXfrYPLxxIaSritV31+rb+xmSDKLMgw0/909sGHDXbrXuYHk80Zedr64+Hz5ZWQUVdB4s6Jzi\n53ftAsXy+9dvr4XkXTsZRKFH7Z53Xx193X+RdP9gQ+eN7yH9t/izf1Rt+8b2ff9ufmf/9aE4\npN+bE3t/6WWTx7aYX7uQPg5/L1B0P8LZ8Cdv7X+5PLxIQKGQ/u6esLO+M/W6e9D479kbi8MT\nEo5/a/OFmt+HN/5uv07zd/vJ1vPmkbg/ywv3y14Wy9/rYP69bh/Q+7V+a/clos2f/PjY/71A\n0f0IZ8OfvLX/5Wz43Jbk8SkU0vpf7u0txaUvyG4fNDv9W+u7Y4uPVefW4/Dl0l+HRwXeopD+\nvRz+ePOlov0XZH9s3uFtZ9h/jnSu6H6E4xjdRyDOPtTpF2RzW5LHp1RI6ztZ20fALzxFaPX3\nufNkvN3fetndyzrcBGyeCrR7EP3X5m+9/dl8xSd6pODPj+23Uew/xtuPxXL/Vd239cf4eXzU\n7kxx8hEOY1wJ6fQpQncvSBrhQU4RT3WZlgc5AQ1JpuVBTkBDkml5kBPQkGRaPAFFCmBIIgUw\nJJECGJJIAQxJpACGJFIAQxIpgCGJFMCQRApACuld30P7+AMmMCR9tXz8AROkQnoXwVIqkX54\ni6Svlo8/YAJD0lfLxx8wgSHpq+XjD5jAkPTV8vEHTGBI+mr5+AMmMCR9tXz8ARMYkr5aPv6A\nCQxJXy0ff8AEhqSvlo8/YAJD0lfLxx8wgSHpq+XjD5jAkPTV8vEHTGBI+mr5+AMmMCR9tXz8\nARMYkr5aPv6ACQxJXy0ff8AEhqSvlo8/YAJD0lfLxx8wgSHpq+XjD5jAkPTV8vEHTGBI+mr5\n+AMmMCR9tXz8ARMYkr5aPv6ACQxJXy0ff8AEhqSvlo8/YAJD0lfLxx8wgSHpq+XjD5jAkPTV\n8vEHTGBI+mr5+AMmMCR9tXz8ARMYkr5aPv6ACUYM6XPoX6DvWR9MaEgx9D3rgwkNKYa+Z30w\noSHF0PesDyY0pBj6nvXBhIYUQ9+zPpjQkGLoe9YHExpSDH3P+mDCRkIaXBJ9z/pgQkOKoe9Z\nH0xoSDH0PeuDCQ0phr5nfTChIcXQ96wPJjSkGPqe9cGEhhRD37M+mNCQYuh71gcTGlIMfc/6\nYEJDiqHvWR9MaEgx9D3rgwkNKYa+Z30woSHF0PesDyY0pBj6nvXBhK2ENLQk+p71wYSGFEPf\nsz6Y0JBi6HvWBxMaUgx9z/pgQkOKoe9ZH0xoSDH0PeuDCQ0phr5nfTChIcXQ96wPJjSkGPqe\n9cGEhhRD37M+mNCQYuh71gcTGlIMfc/6YEJDiqHvWR9MaEgx9D3rgwkNKYa+Z30woSHF0Pes\nDyZsJqSBJdH3rA8mNKQY+p71wYSGFEPfsz6Y0JBi6HvWBxMaUgx9z/pgwpmFtFwTXe6BIekb\nUTivkJbH/5xe7oMh6RtRaEgx9D3rgwnnFdIWQ9LHEz5MSO+3+Lz5HiIjUbyVq/QLadn91Vsk\nfQzh/G6RDEkfUDi7kJYnFwxJH0M4t5CWp5cMSR9DOLOQlmcXDUkfQzivkJbL/dMZliuf2aCP\nJJxXSBkMSd+IQkOKoe9ZH0xoSDH0PeuDCdsJaVhJ9D3rgwkNKYa+Z30woSHF0PesDyY0pBj6\nnvXBhIYUQ9+zPpjQkGLoe9YHExpSDH3P+mBCQ4qh71kfTGhIMfQ964MJDSmGvmd9MKEhxdD3\nrA8mNKQY+p71wYSGFEPfsz6Y0JBi6HvWBxMaUgx9z/pgwoZCGlQSfc/6YEJDiqHvWR9MaEgx\n9D3rgwkNKYa+Z30woSHF0PesDyY0pBj6nvXBhIYUQ9+zPpjQkGLoe9YHExpSDH3P+mBCQ4qh\n71kfTGhIMfQ964MJWwppSEn0PeuDCQ0phr5nfTChIcXQ96wPJjSkGPqe9cGEhhRD37M+mNCQ\nYuh71gcTGlIMfc/6YEJDiqHvWR9MaEgx9D3rgwkNKYa+Z30woSHF0PesDyY0pBj6nvXBhIYU\nQ9+zPpjQkGLoe9YHExpSDH3P+mBCQ4qh71kfTNhUSANKou9ZH0xoSDH0PeuDCQ0phr5nfTCh\nIcXQ96wPJjSkGPqe9cGEhhRD37M+mNCQYuh71gcTGlIMfc/6YEJDiqHvWR9MaEgx9D3rgwkN\nKYa+Z30woSHF0PesDyY0pBj6nvXBhIYUQ9+zPpjQkGLoe9YHExpSDH3P+mBCQ4qh71kfTGhI\nMfQ964MJDSmGvmd9MKEhxdD3rA8mbCuk/iXR96wPJjSkGPqe9cGEhhRD37M+mNCQYuh71gcT\nGlIMfc/6YEJDiqHvWR9MaEgx9D3rgwkfJqT3Xnz2ezeRopRKpB/eIumr5eMPmMCQ9NXy8QdM\nYEj6avn4AyYwJH21fPwBExiSvlo+/oAJDElfLR9/wASGpK+Wjz9gggoh9S6Jvmd9MKEhxdD3\nrA8mNKQY+p71wYSGFEPfsz6Y0JBi6HvWBxMaUgx9z/pgQkOKoe9ZH0xoSDH0PeuDCQ0phr5n\nfTBhayH1LYm+Z30woSHF0PesDyY0pBj6nvXBhIYUQ9+zPpjQkGLoe9YHExpSDH3P+mBCQ4qh\n71kfTGhIMfQ964MJmwupZ0n0PeuDCQ0phr5nfTChIcXQ96wPJjSkGPqe9cGEhhRD37M+mNCQ\nYuh71gcTGlIMfc/6YEJDiqHvWR9MaEgx9D3rgwkNKYa+Z30wYXsh9SuJvmd9MKEhxdD3rA8m\nNKQY+p71wYSGFEPfsz6Y0JBi6HvWBxMaUgx9z/pgQkOKoe9ZH0xoSDH0PeuDCQ0phr5nfTCh\nIcXQ96wPJjSkGPqe9cGEhhRD37M+mLDBkHqVRN+zPpjQkGLoe9YHExpSDH3P+mBCQ4qh71kf\nTGhIMfQ964MJDSmGvmd9MKEhxdD3rA8mNKQY+p71wYSGFEPfsz6Y0JBi6HvWBxMaUgx9z/pg\nwhZD6lMSfc/6YEJDiqHvWR9MaEgx9D3rgwkNKYa+Z30woSHF0PesDyY0pBj6nvXBhIYUQ9+z\nPpjQkGLoe9YHExpSDH3P+mBCQ4qh71kfTNhkSD1Kou9ZH0xoSDH0PeuDCQ0phr5nfTChIcXQ\n96wPJjSkGPqe9cGEhhRD37M+mNCQYuh71gcTzi6k5delDfd9JENq3ccfMEGfkDrpDIno6ezt\nmyXR96wPJpxZSMuVIekjCmcWUiefQffqDEnfuMIZh3T6KdL7VZ7O3v68/u4iRSkfyzXuuEXq\ne7PkLZK+cYXzvUUK3rqMIekbV2hIMfQ964MJ5xuSd+30gYTzDqn3I3fnId0sib5nfTDhTEPa\nVjTgiQ2GpG9c4exCug9D0jeusJGQBn+SRN+zPpjQkGLoe9YHExpSDH3P+mBCQ4qh71kfTGhI\nMfQ964MJWw3pVkn0PRf2PW0oKYRf3xkMmMCQJvKtG3pf7WsqlBP6+o4hNKQY+p4L+rbtvHfe\nLNET+PqOIzSkGPqei/n2yXzzJXPCXt+xhIYUQ99zId8xlQu+u3OCXt/xhIYUQ99zEV8nkau+\nO+7tIa/vmEJDiqHvuYDvpIw+viE5Aa/vuEJDiqHvOes7L6K/r9/NE+36ji40pBj6nnO+7x0M\n9t3IiXV9KwibDelGSfQ9Z3zR+X+n72JOpOtbRWhIMfQ93++Lb0ZS8wX39jjXt5LQkGLoe77X\nd+neWIn5ujlRrm81oSHF0Pd8n+/yJzXl5ivzzIhzDGkAhjSu79rZXXy+wjkZ0gAMaUTfjbN6\npPmK3TwZ0gBG/UFjAx//pu95oG/ir/vkczKkARjSSL4e53CN+TI5GdIADGkUX69zt958993b\nM6QBGNIIvp6nbPX5BuZkSAOoG9L1kuh77unrfapONl/PngxpAIZU2Dfhv/jDfLdzMqQBGFJJ\n37DPQwjX99rNkyENwJDK+YZ+Ng+6vmFOhjQAQyrlG/4gM+76nuVkSAMwpDK+e75WA72+x3t7\nhjQAQyrhu+9LnuzrO8LzYNlXOIch5X2UZw6M4Sv6vHL6Fc4wakgDvyJL33Psu/8sm9H1LZMT\n/QpnMKScL3N2ze76ZnOiX+EMlUO6WhJ9z9GJVdSXpJLv/nt79CucYdyQht0k0fd85nv41+q+\n9XD/4JzoVzjDI4dU+nuvT+YrIKefV318g26e6Fc4wwOH9PSeve91xskn32V9RZj020b65ES/\nwhkeO6RV0Zul43yFnPTzarDv1s3T5AOOyOOG9HTwlf4ySLE06efVvb75voJlggZCWpVqabRb\nuIf0BTmxBizLw4Z0/lyxIl9PHO1zrof1ndzbIw5YimZCWuVbGvVRwMf27XICD5jmUUM6/Rmt\nX799fwv884DuK/6CsC2HdK2kCiHdfbM0xrcVtObrPPpT8JNWCCOHNOgmqeRdiWu+4Ufx6arv\nXlrzffukFfcKlglaDGk1sKW5fK5M91141i/oFSwTPGZITz18fQ/f17vRT1S674rwvpwMKaZu\nSKs+Dz2cHF36iUr33RQOvbdnSDHF9tL/rtj1wzazryfSfX2FvXMypJgJQlpdaWn0l6dqzTdM\n2OPmyZBiSu3l8DF7+6LjFfwW/USl++4SXsvJkGIK7eWuBwfODtYsn3NJ9yWEcU5Nh3SlpClD\nWnXjqfQSvq350sLze3uGFFNmL4k97w7Sxfvl9BOV7iv2L+UhJ0OKmTyk1fWH8egnKt1X+FnJ\n5Z/8mOHhQvLrPlgff8AEhtQffTChIcWU2Ev349GPW2s+/oAJDKk/+mDCtkO6XFKBvZx8OPpx\na83HHzCBIfVHH0xoSDH5vfgkU7KPP2CCsUMa8kmSIT22jz9ggocK6exj0Y9baz7+gAkMqT/6\nYEJDikk/p7Gw7xx9MGHjIV0sKbmX0Z9lrw8mNKQYQ3psH3/ABI8Tkt/RSvfxB0xgSP3RBxM+\nTEjvPXj6/lufff7eUIKPI01TKpF+jH6LNOBhu9RVD2756P8AtubjD5jgUULyxUr4Pv6ACcYP\nqX9JhvTYPv6ACR4kpPCFFujHrTUff8AEhtQffTChIcXveP9efB26Ofj4AyYwpP7ogwkNKX7H\nu/dS6aWh9cGEhhS/oyE9to8/YIIKIfUu6d69+BLD8/DxB0zwACFdfI1h+nFrzccfMIEh9Ucf\nTGhIQ0O6+vMpL/4J/bi15uMPmGAmIV35GRGGNBcff8AEswjp2k8tunJjRT9urfn4AyaYTUiX\nUjKk2fj4AyaYJqS4pBshhSld++yJftxa8/EHTDCrkIKUDGk+Pv6ACeYQ0tPFN652hD9urfn4\nAyaYXUinN0qGNCMff8AE8wupm9LVjvDHrTUff8AEMwgp+OuHlAxpTj7+gAlqhNT38e/+Ie1T\nut4R/ri15uMPmGCikMKShoS0TcmQZuXjD5hgviHdvEHCH7fWfPwBE/BDupXLZejHrTUff8AE\nhqSvlo8/YAJD0lfLxx8wgSHpq+XjD5gAH9L9HeGPW2s+/oAJpgopKsmQHtvHHzCBIemr5eMP\nmIAeUqIj/HFrzccfMIEh6avl4w+YoEpIPR9tMKTH9vEHTHAW0st/o3wUQ9I3ghAc0nKcW6h+\n9+2CvWQ6wh+31nz8AROchfP35fXfCB/lKUjCkFrz8QdMcBbS4kjRj/IUvACQIbXm4w+YoFJI\nwfcO9Qkp1RH+uLXm4w+YoNqjdobUvI8/4DVulFInpJUh6ZvBgB2GhnH+/h+vz4vF8+tHqXm+\nOI/CkFrz8QfskAzp33L3GdKy/GN3t2+Svu0l1xH+uLXm4w/4xfZhgvX/LfYXt6Vs3r4U2Nnv\n/7d4WSf072VR/guzhtS6jzXgZ8zhj7ft7APaV9R5+zvfHrU7/bUghtS6jz9gh9NmFof/N6QC\n6IMJK4W0u283LCTUXbtkR/jj1pqPP2CHr5COnyANCQn1YIMhPZaPP2CH7qdHd4RU8eFvQ2rN\nxx+ww0lIw+/ajcjtFwB/uvrmcOjHrTUff8AOu4e/O5eGhTTS9yNtuXmTdPbEVkN6MB9/wAR1\nvh9py62Qnt4N6aF9/AET1Pl+pC23Q7r2Qy7vgH7cWvPxB0xQ59sotvQIqfs+6Y7wx601H3/A\nBIakr5aPP2CCeo/a3XrY7mm7l6fO21nox601H3/ABFM+aheFdHyvfEf449aajz9ggikftTOk\ntnz8ARNUfNTuxidJ+5AO72VID+fjD5ig4oMN10N6Ou7lKX7n4dCPW2s+/oAJgCFt369AR/jj\n1pqPP2CCio/a7eI4KeTz5A8N6bF9/AETEEMKX73rDujHrTUff8AE30L69WN9t+7l7xgfa3tL\ncyGkzW+/d94ypMfz8QdMcBbSx/Pu5VMWbyN8rAEhlegIf9xa8/EHTPDtW81fN9/F9HvxMsLH\nevp2p+1SSEVukPDHrTUff8AEwYufHP5XnCshbX+Tvmd9MGGrIe0+9Qnv2xlSAz7+gAniu3av\nI7yK0Gr/qY8hterjD9ghuiW5duty/mDDeK8itDKkxn38ATskQ1qtfo71KkKrK19I2v0efc/6\nYMIRQ9q/KOT+KT6nb8V/YbxZvnP2LLonQ2rKxxrwKebwx2cv+/316wWqhrTjK6QnQ2rJxx+w\nw7eQVgVCWn5dWnPvaAe+vuPoeJNkSC34+AN22L0u5OFHuny9ePG197/FVzvL438SdL51b3+T\ntP8d+p71wYRVbpH2b175iS7H97/BcmVI+ojCiiGV+RxptJBWT4bUjo8/YIdRHmy4FNL7XTx1\nfnn67PyOSEHuqKcbxveHv6/84MtJbpFOHgXvfomW/g+WPpgQ/BShmBFD6j77jr5nfTChIX39\n15Da8fEHTDBZSId6Pp8MqREff8AEgJCOz3Sg71kfTDjTkDb/LfHMhrOQVobUiI8/YIIJnmt3\n+n2ynRcSou9ZH0xoSN1vpvgqib5nfTChIRlSiz7+gAkMSV8tH3/ABBOF1Pk2WUNqxccfMIEh\n6avl4w+YYJKQTl5J1ZBa8fEHTDB9SF8l0fesDyY0pPgFwOl71gcTGpIhtejjD5hgmpBOMKRG\nfPwBExiSvlo+/oAJACEdS6LvWR9MaEinGFIbPv6ACQxJXy0ff8AEhqSvlo8/YAJD0lfLxx8w\ngSHpq+XjD5iAENKhJPqe9cGEhnSGITXh4w+YwJD01fLxB0xgSPpq+fgDJjAkfbV8/AETGJK+\nWj7+gAkQIe1Lou9ZH0xoSOcYUgs+/oAJDElfLR9/wASGpK+Wjz9gAkPSV8vHHzABI6RdSfQ9\n64MJDekbhtSAjz9gAkPSV8vHHzCBIemr5eMPmMCQ9NXy8QdMYEj6avn4AyaAhLQtib5nfTCh\nIX3HkB7fxx8wgSHpq+XjD5jAkPTV8vEHTGBI+mr5+AMmMCR9tXz8ARNQQtqURN+zPpjQkAIM\n6eF9/AETGJK+Wj7+gAkMSV8tH3/ABIakr5aPP2ACTEjrkuh71gcTGlKEIT26jz9gAkPSV8vH\nHzCBIemr5eMPmMCQ9NXy8QdMYEj6avn4AybghLT6pO9ZH0xoSCGG9OA+/oAJDElfLR9/wASG\npK+Wjz9gAkPSV8vHHzCBIemr5eMPmAAU0uEnYBaDftxa8/EHTGBI+mr5+AMmMCR9tXz8ARMY\nkr5aPv6ACUghvRcuiX7cWvPxB0xgSPpq+fgDJjAkfbV8/AETGJK+Wj7+gAlQIRV+uIF+3Frz\n8QdMYEj6avn4AyYwJH21fPwBExiSvlo+/oAJWCGVLYl+3Frz8QdMYEj6avn4AyZIhfRenM/y\nSmmUUon0w1skfbV8/AETwEIqWhL9uLXm4w+YwJD01fLxB0xgSPpq+fgDJqCFVLIk+nFrzccf\nMIEh6avl4w+YwJD01fLxB0xgSPpq+fgDJsCFVLAk+nFrzccfMIEh6avl4w+YwJD01fLxB0xg\nSPpq+fgDJuCFVK4k+nFrzccfMIEh6avl4w+YwJD01fLxB0wADKlYSfTj1pqPP2ACQ9JXy8cf\nMIEh6avl4w+YwJD01fLxB0xADKlUSfTj1pqPP2ACQ9JXy8cfMIEh6avl4w+YwJD01fLxB0yA\nDKlQSfTj1pqPP2ACQ9JXy8cfMIEh6avl4w+YwJD01fLxB0zADKlMSfTj1pqPP2ACQ9JXy8cf\nMIEh6avl4w+YABpSkZLox601H3/ABIakr5aPP2ACQ9JXy8cfMAE1pBIl0Y9baz7+gAkMSV8t\nH3/ABNiQCpREP26t+fgDJjAkfbV8/AETGJK+Wj7+gAm4IeVLoh+31nz8ARMYkr5aPv6ACQxJ\nXy0ff8AE4JDSJdGPW2s+/oAJDElfLR9/wASGpK+Wjz9gAnJI2ZLox601H3/ABIakr5aPP2AC\ndEjJkujHrTUff8AEhqSvlo8/YAJD0lfLxx8wATukXEn049aajz9gAkPSV8vHHzCBIemr5eMP\nmAAeUqok+nFrzccfMIEh6avl4w+YgB5SpiT6cWvNxx8wgSHpq+XjD5jAkPTV8vEHTIAPKVES\n/bi15uMPmMCQ9NXy8QdMYEj6avn4Aybgh3R/SfTj1pqPP2ACQ9JXy8cfMIEh6avl4w+YYAYh\n3V0S/bi15uMPmMCQ9NXy8QdMMIeQ7i2Jftxa8/EHTGBI+mr5+AMmMCR9tXz8ARPMIqQ7S6If\nt9Z8/AETGJK+Wj7+gAnmEdJ9JdGPW2s+/oAJDElfLR9/wAQzCemukujHrTUff8AEhqSvlo8/\nYIIeIS3XdC8vr71zhqt7uaMk+nFrzccfMMHtkJbH/3R+HQVDemwff8AEswnpjpLox601H3/A\nBMNCGrUjQ3pwH3/ABANDOv0U6b0qn3U/nMycUXq5yB23SNM82HDHTRL9H8DWfPwBEwz8HOn8\nclFu7WVoSfTj1pqPP2ACQ9JXy8cfMMGM7toNLol+3Frz8QdMMDyk8R65u72XYSXRj1trPv6A\nCQY8s2HZuTwKhvTYPv6ACebyXLs9g0qiH7fWfPwBExiSvlo+/oAJZhbSoJLox601H3/ABIak\nr5aPP2CCuYU0pCT6cWvNxx8wgSHpq+XjD5hgdiENKIl+3Frz8QdMYEj90QcTGlJMz730Lol+\n3Frz8QdMYEj90QcTGlJM3730LYl+3Frz8QdMYEj90QcTGlJM7730LIl+3Frz8QdMMMuQepZE\nP26t+fgDJjCk/uiDCQ0pZsBeepVEP26t+fgDJjCk/uiDCQ0pZshe+pREP26t+fgDJjCk/uiD\nCQ0pZtBeepREP26t+fgDJjCk/uiDCQ0pZthebpdEP26t+fgDJjCk/uiDCQ0pZuBebpZEP26t\n+fgDJjCk/uiDCQ0pZuhePreU891CH0xoSDH37eXzSBnfZfTBhIYUk93L51lT9OPWmo8/YIJH\nCqnDhduoHPTzgO7jD5jgQUPa+8qmRD8P6D7+gAkeO6RV0ZTo5wHdxx8wwaOHVDIl+nlA9/EH\nTPD4IZVLiX4e0H38ARO0EFKplOjnAd3HHzBBGyGVSYl+HtB9/AETtBJSiZTo5wHdxx8wQTsh\nbb+4VNSXpTUff8AELYW0St4s0c8Duo8/YILGQkqlRD8P6D7+gAmaCymREv08oPv4AyZoMKS7\nUyo5X4vPBeQPmKDJkO5MqcR83aenv6cf/jgFf57iB0zQaEh3pZSZL/qeqff9HyS0J+DPU/yA\nCZoN6Y6U7pnv0jcddn2lWsKfp/gBEzQc0uCUBsx38bt2L/iKtIQ/T/EDJmg6pIEncD9f/0cR\nWnvmBX/ABI2HtBpyAl998OKOh+Fae+YFf8AEhtQ/pfCZEonHsWPfXapLvhSGNABD2tDv9D39\nnCb/haB4vvut+PMUP2ACQ9rR5+x97/cYQm+ufMH4rg+AP0/xAyYwpAPXTt6i/Ry5Nt89Hwx/\nnuIHTGBIX3w/d08Dqv51roEtTb2/6kJDipl+z4dTN74Fqj/fsJam319loSHFEPZ87S7cJPMN\naImwv6pCQ4qh73mGD8+nMKQBGNIcfP1ulujXlz9gAkOaia9HS/Tryx8wgSHNx3erpannqy40\npBj6ngG+WdFUI5YAAAdJSURBVP9gNf6ACQxpbr7LLTHmqyg0pBj6njG+G98oWApDGoAhzdMX\ntUSar4rQkGLoe4b5AM+8mFhoSDH0PfN8wYupFMSQBmBI8/Z1b5aI840qNKQY+p6hvqmenT69\n0JBi6Hvm+nYtcecbSWhIMfQ9o33rltDzjSE0pBj6num+0t/Ca0gDMKSH8hVtyZAGYEiP5ivX\nkiENwJAe0FeoJUMaQCqkd6Hy+Tn1BJNTKpF+eIv0qL78zZK3SAMwpAf2JVsypAEY0mP7Mi0Z\n0gAM6eF9d7dkSAMwpBZ897VkSAMwpEZ8d7RkSAMwpHZ82R+Eloa+wAyG1JSv9I/6HAZ9gRkM\nqTVf/5YMaQCG1KDvrh8WXQD6AjMYUpO+XjdLhjQAQ2rVd7slQxqAITXsu9GSIQ3AkNr2XWvJ\nkAZgSM37qv2EQsoVHgVD0nepJUMagCHp2xK0ZEgDMCR9B85bMqQBGJK+DicpGdIADEnfCZ2b\nJUMagCHpO+fQkiENwJD0BWxbMqQBGJK+mNIvgLyiX+EchqTvoo/+YuKGFEPfc4s+9IuJG1IM\nfc+N+rgvJm5IMfQ9t+uDvpi4IcXQ99y0r0RK9CucwZD09fTxXkzckGLoe9YHezFxQ4qh71nf\nivVi4oYUQ9+zvh2YFxM3pBj6nvUdYbyYuCHF0PesrwvgxcQNKYa+Z31nTP1i4oYUQ9+zvu9M\n+mLihhRD37O+kP4p0a9wBkPSl/b1vVmiX+EMhqSvhG+SFxM3pBj6nvVdpf6LiRtSDH3P+m5R\n+cXEDSmGvmd9Paj5YuKGFEPfs75+VHsxcUOKoe9ZX2/qvJi4IcXQ96xvCBVeTNyQYuh71jeQ\nsV9M3JBi6HvWN5xRX0zckGLoe9Z3DyO+mLghxdD3rO9OxnoxcUOKoe9Z3/2M8mLihhRD37O+\nFOVfTNyQYuAngr60sHBLhhRDPxH0FRCWbMmQYugngr4ywmItGVIM/UTQV0xYpiVDiqGfCPpK\nCgukZEgx9BNBX1lh+mbJkGLoJ4K+4sJcS4YUQz8R9I0hTLRkSDH0E0HfSMJ7WzKkGPqJoG88\n4V0tGVIM/UTQN6pweEuGFEM/EfSNLRzYkiHF0E8EfRWEQ1oypBj6iaCvjrB3SoYUQz8R9NUS\n9rxZMqQY+omgr6KwT0uGFEM/EfTVFd5syZBi6CeCvurC6y0ZUgz9RNA3hfBKS4YUQz8R9E0k\nvNSSIcXQTwR90wnDlgwphn4i6JtU+L0lQ4qhnwj6phaO/FriGXqEtFwTXS4O/UTQN73w5GZp\nXiEtj/85vVwe+omgDyH8asmQYugngj6KcN+SIcXQTwR9IOGmpYcJ6V1kOj6v//EYuVzGWyR9\ntXz8ARMYkr5aPv6ACQxJXy0ff8AEhqSvlo8/YAJD0lfLxx8wwYBnNiw7l0eBvmd9MOHMQqoG\nfc/6YEJDiqHvWR9MaEgx9D3rgwkNKYa+Z30woSHF0PesDyY0pBj6nvXBhIYUQ9+zPpjQkGLo\ne9YHExpSDH3P+mBCQ4qh71kfTGhIMfQ964MJDSmGvmd9MKEhxdD3rA8mNKQY+p71wYSGFEPf\nsz6Y0JBi6HvWBxMaUgx9z/pgQkOKoe9ZH0xoSDH0PeuDCQ0phr5nfTChIcXQ96wPJjSkGPqe\n9cGEhhRD37M+mNCQYuh71gcTGlIMfc/6YEJDiqHvWR9MaEgx9D3rgwkNSeTBMCSRAhiSSAEM\nSaQAhiRSAEMSKYAhiRTAkEQKYEgiBTAkkQI8WkjdH7t+/HHso/4s9mGczzf6j4ofSGeWZXc+\nzIDrcb4udQ7wZOPsebCQlsf/dC5PvuQvuvN9mxPAt1lg+1ttqjle2v8HsUBDqsrcQiLNtmO5\nMqQKRP+iTr3iLt9CX0HOgz1RSJDRjhhSBcKQCHeh95yEdPgUpPN7U3M2C+5TzA2GVIGL/6JO\nvec90V1P6nwnb0Lm22BIFQjv45/93pRcvOvJnC+6NDmGVAH6iTCvkKJ/kabHkCoQnQiIPe+Z\n11073v42GFIFLj28PPWaD5yHRP4crhsSZLwthlSD4xe7V6dfmZ94rCOd+VBfmD/Qna/78OJ0\nE32jkzdogY8WksgkGJJIAQxJpACGJFIAQxIpgCGJFMCQRApgSCIFMCSRAhiSSAEMaXJe98fg\nY/G82F18WSz+TDiQ3IEhTc3rvp7V78XP3UU7miGGNDH/LQ4hvSz+bi++LJb/Jh1J7sCQpmW5\nfDuEtFiuNhftaJYY0rS8rlb7kP4sXjcXXxYvE48k92BIk7MP6b/F2/ricrH4PfE8cg+GNDn7\nkNb37NYXNyV5z26GGNLk7EJ6W/y3ufi6vm/3PPVEMhxDmpxdSK+bh7w3F/8tN0nJzDCkydmF\ntFwcLr75adIMMaTJ2dbzb3sztGvql58mzQ9DmpxtPT+3T2Y4PoDnQ+Bzw5AmZ1vP8+J4cbX5\nouzrhAPJHRiSSAEMSaQAhiRSAEMSKYAhiRTAkEQKYEgiBTAkkQIYkkgB/gcE5HBNgp1zugAA\nAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot misclassification errors for train and test data sets\n",
    "miss.m <- melt(miss, id='K') # reshape for visualization\n",
    "names(miss.m) <- c('K', 'type', 'error')\n",
    "ggplot(data=miss.m, aes(x=1/K, y=error, color=type)) + geom_line() +\n",
    "       scale_color_discrete(guide = guide_legend(title = NULL)) + theme_minimal() +\n",
    "       ggtitle(\"Root Mean Square Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1-3**\n",
    "\n",
    "Q1-3)Report the best value for K in terms of the testing error. Discuss the values of K corresponding to underfitting and overfitting based on your plot in the previous sub-question, Q1-2.\n",
    "\n",
    "**Answer**\n",
    "\n",
    "The main goal of machine learning is *mathematical optimisation*--that is, minimising the error function.\n",
    "\n",
    "Therefore, the optimal K brings out the least amount of testing errors (in this case the *root mean squared-errors*), which is when **K = 11** (0.95). It's nice to note that **K = 9 and K = 10** gives out some pretty low errors as well (0.98 and 1.02 respectively).\n",
    "\n",
    "An overfitted model is a model where K is at the lowest because it becomes too restrictive; it just relies on a single neighbour to determine the target variable of a point. Thus, it is when **K = 1**. Also note that overfitting *in general* happens when the **training error = 0**, which is also when **K = 1.** Looking at the plot and the errors, it is overfitted when **K = 1 to 4**, with all of the errors >= 1.30. The model is still too restrictive for the data even with K = 2 to 4.\n",
    "\n",
    "On the other hand, an underfitted model is a model where K is at a very high value (**K = number of variables**) because K becomes too flexible; the resulting prediction will just come from a few set of values. When **K = N**, the model produces only a single predicted value--the average of all the points. Looking at the plot, it can easily be seen as **K = 16 and above**, with all of the errors >= 1.20.\n",
    "\n",
    "Both underfitted and overfitted models give out high testing errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2 [K-fold Cross Validation, 20 Marks] \n",
    "Q2-1) Implement a K-fold Cross Validation (CV) function for your KNN regressor:  \n",
    "       cv(train.data, train.label, numFold=10) \n",
    "which takes the training data and their labels (continuous values), the number of folds, and returns errors for different folds of the training data. \n",
    "\n",
    "__Hint__: you are allowed to use bootstrap code from Activity 2 of Module 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Q2-1**\n",
    "\n",
    "First, implemented a method that divides the dataset into **K-folds**.\n",
    "\n",
    "This method divides the dataset into **K** equal-sized distinct subsets, and use  one of these subsets for *testing* while the other **K-1** subsets for *training*. The method is repeated K times until every subset has been used for testing, and the resulting error comes from the average of all the errors computed per Kth iteration. This ensures that every observation has been used for both training and testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters:\n",
    "# train.data - a dataframe of data\n",
    "# numFold - the k in K-fold\n",
    "# returns: \n",
    "create_folds <- function(train.data, numFold = 10){\n",
    "    \n",
    "    # shuffle the indices\n",
    "    shuffled.indices <- sample(nrow(train.data), nrow(train.data), replace = FALSE)\n",
    "    shuffled.indices\n",
    "    \n",
    "    # get the number of elements per K, take care of the remainder\n",
    "    k.length <- round(nrow(train.data)/numFold)\n",
    "    k.length.remainder <- nrow(train.data)%%numFold\n",
    "\n",
    "    remainder.counter <- 1\n",
    "    start <- 1\n",
    "\n",
    "    folds <- array(list(), numFold)\n",
    "\n",
    "    # divide the indices per fold\n",
    "    for (j in 1:numFold){\n",
    "        stop <- start + k.length - 1\n",
    "        \n",
    "        # take care of the remainder; distribute them to the initial folds\n",
    "        if (remainder.counter <= k.length.remainder) {\n",
    "            stop <- stop + 1\n",
    "            remainder.counter <- remainder.counter + 1\n",
    "        } \n",
    "\n",
    "        # pass the list of shuffled indices\n",
    "        elements <- shuffled.indices[start:stop]\n",
    "        folds[[j]] <- as.list(elements)\n",
    "\n",
    "        start <- stop + 1\n",
    "    }\n",
    "        \n",
    "    return(folds)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below defines the cross-validation proper. It uses the *create_folds()* function defined earlier to distribute the dataset into K-folds, then implements KNN per fold. The resulting errors are then recorded and then returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameters:\n",
    "# train.data - a dataframe of data (input variables)\n",
    "# train.label - a dataframe of values (target variable)\n",
    "# numFold - the k in K-fold\n",
    "# maxK - the maximum K of KNN (minimum is always 1)\n",
    "cv <- function(train.data, train.label, numFold = 10, maxK = 20){\n",
    "    K <- maxK\n",
    "    \n",
    "    # create a matrix of errors, where the row indicates K\n",
    "    # and the column indicates the fold \n",
    "    errors <- matrix(nrow = K, ncol = numFold + 1)\n",
    "    \n",
    "    # set the first column values as \"index\"\n",
    "    errors[,1] <- c(1:K)\n",
    "\n",
    "    # divide the dataset into K-folds\n",
    "    f <- create_folds(train.data, numFold)\n",
    "    \n",
    "    # split per fold into testing and training subgroups\n",
    "    for (i in 1:numFold) {\n",
    "\n",
    "        # generate test group indices - test group is the ith fold\n",
    "        test.indices <- c()\n",
    "        for (k in 1:length(f[[i]])){\n",
    "            test.indices <- c(test.indices, f[[i]][[k]])\n",
    "        }\n",
    "\n",
    "        train.indices <- c()\n",
    "\n",
    "        # generate the train group indices for the remaining folds\n",
    "        for(j in 1:numFold) {\n",
    "            if (j != i) {\n",
    "                for (k in 1:length(f[[j]])){\n",
    "                    train.indices <- c(train.indices, f[[j]][[k]])\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # retrieve the data and labels\n",
    "        trn.dt <- train.data[train.indices,]\n",
    "        trn.vl <- train.label[train.indices]\n",
    "\n",
    "        tst.dt <- train.data[test.indices,]\n",
    "        tst.vl <- train.label[test.indices]\n",
    "\n",
    "        # convert to data frame\n",
    "        trn.df <- as.data.frame(trn.dt) \n",
    "        colnames(trn.df) <- c(\"data\")\n",
    "\n",
    "        tst.df <- as.data.frame(tst.dt)\n",
    "        colnames(tst.df) <- c(\"data\")\n",
    "\n",
    "        # generate the errors per K\n",
    "        for (k in 1:K){\n",
    "            errors[k, i + 1] <- get.rmse(knn(trn.df, trn.vl, tst.df, k, 'euclidean'), tst.vl)\n",
    "        }\n",
    "\n",
    "    }\n",
    "\n",
    "    return (errors)   \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2-2**\n",
    "\n",
    "Q2-2) Using the training data, run your K-fold CV where the numFold is set to 10. Change the value of K=1,..,20 and for each K compute the average 10 error numbers you have got.  Plot the average error numbers versus 1/K for K=1,..,20. Further, add two dashed lines around the average error indicating the average +/- standard deviation of errors. Include the plot in your report. \n",
    "\n",
    "Using the matrix **result** that came from the *cv()* method, create a new data.frame the computes the average values of the folds per K. This will be the final RMSE per K, and will be used to determine the optimum model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>K</th><th scope=col>RMSE</th><th scope=col>plus.SD</th><th scope=col>minus.SD</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 1       </td><td>0.6666252</td><td>0.9683018</td><td>0.3649486</td></tr>\n",
       "\t<tr><td> 2       </td><td>0.5863092</td><td>0.8959891</td><td>0.2766293</td></tr>\n",
       "\t<tr><td> 3       </td><td>0.4451225</td><td>0.6693854</td><td>0.2208595</td></tr>\n",
       "\t<tr><td> 4       </td><td>0.5242669</td><td>0.8486838</td><td>0.1998501</td></tr>\n",
       "\t<tr><td> 5       </td><td>0.5351558</td><td>0.9406435</td><td>0.1296680</td></tr>\n",
       "\t<tr><td> 6       </td><td>0.6769351</td><td>1.1712122</td><td>0.1826581</td></tr>\n",
       "\t<tr><td> 7       </td><td>0.7916834</td><td>1.4233227</td><td>0.1600440</td></tr>\n",
       "\t<tr><td> 8       </td><td>0.9174916</td><td>1.6246256</td><td>0.2103575</td></tr>\n",
       "\t<tr><td> 9       </td><td>0.9699439</td><td>1.8386158</td><td>0.1012721</td></tr>\n",
       "\t<tr><td>10       </td><td>1.1358160</td><td>2.0308027</td><td>0.2408292</td></tr>\n",
       "\t<tr><td>11       </td><td>1.1645582</td><td>2.1944200</td><td>0.1346964</td></tr>\n",
       "\t<tr><td>12       </td><td>1.2500835</td><td>2.3596040</td><td>0.1405630</td></tr>\n",
       "\t<tr><td>13       </td><td>1.3719006</td><td>2.5215587</td><td>0.2222425</td></tr>\n",
       "\t<tr><td>14       </td><td>1.4925942</td><td>2.6848004</td><td>0.3003881</td></tr>\n",
       "\t<tr><td>15       </td><td>1.5725921</td><td>2.8375952</td><td>0.3075891</td></tr>\n",
       "\t<tr><td>16       </td><td>1.6490359</td><td>2.9823272</td><td>0.3157445</td></tr>\n",
       "\t<tr><td>17       </td><td>1.7149013</td><td>3.1453657</td><td>0.2844368</td></tr>\n",
       "\t<tr><td>18       </td><td>1.8432590</td><td>3.3012844</td><td>0.3852336</td></tr>\n",
       "\t<tr><td>19       </td><td>1.8721876</td><td>3.4490067</td><td>0.2953685</td></tr>\n",
       "\t<tr><td>20       </td><td>1.9819118</td><td>3.6065065</td><td>0.3573171</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " K & RMSE & plus.SD & minus.SD\\\\\n",
       "\\hline\n",
       "\t  1        & 0.6666252 & 0.9683018 & 0.3649486\\\\\n",
       "\t  2        & 0.5863092 & 0.8959891 & 0.2766293\\\\\n",
       "\t  3        & 0.4451225 & 0.6693854 & 0.2208595\\\\\n",
       "\t  4        & 0.5242669 & 0.8486838 & 0.1998501\\\\\n",
       "\t  5        & 0.5351558 & 0.9406435 & 0.1296680\\\\\n",
       "\t  6        & 0.6769351 & 1.1712122 & 0.1826581\\\\\n",
       "\t  7        & 0.7916834 & 1.4233227 & 0.1600440\\\\\n",
       "\t  8        & 0.9174916 & 1.6246256 & 0.2103575\\\\\n",
       "\t  9        & 0.9699439 & 1.8386158 & 0.1012721\\\\\n",
       "\t 10        & 1.1358160 & 2.0308027 & 0.2408292\\\\\n",
       "\t 11        & 1.1645582 & 2.1944200 & 0.1346964\\\\\n",
       "\t 12        & 1.2500835 & 2.3596040 & 0.1405630\\\\\n",
       "\t 13        & 1.3719006 & 2.5215587 & 0.2222425\\\\\n",
       "\t 14        & 1.4925942 & 2.6848004 & 0.3003881\\\\\n",
       "\t 15        & 1.5725921 & 2.8375952 & 0.3075891\\\\\n",
       "\t 16        & 1.6490359 & 2.9823272 & 0.3157445\\\\\n",
       "\t 17        & 1.7149013 & 3.1453657 & 0.2844368\\\\\n",
       "\t 18        & 1.8432590 & 3.3012844 & 0.3852336\\\\\n",
       "\t 19        & 1.8721876 & 3.4490067 & 0.2953685\\\\\n",
       "\t 20        & 1.9819118 & 3.6065065 & 0.3573171\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "K | RMSE | plus.SD | minus.SD | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "|  1        | 0.6666252 | 0.9683018 | 0.3649486 | \n",
       "|  2        | 0.5863092 | 0.8959891 | 0.2766293 | \n",
       "|  3        | 0.4451225 | 0.6693854 | 0.2208595 | \n",
       "|  4        | 0.5242669 | 0.8486838 | 0.1998501 | \n",
       "|  5        | 0.5351558 | 0.9406435 | 0.1296680 | \n",
       "|  6        | 0.6769351 | 1.1712122 | 0.1826581 | \n",
       "|  7        | 0.7916834 | 1.4233227 | 0.1600440 | \n",
       "|  8        | 0.9174916 | 1.6246256 | 0.2103575 | \n",
       "|  9        | 0.9699439 | 1.8386158 | 0.1012721 | \n",
       "| 10        | 1.1358160 | 2.0308027 | 0.2408292 | \n",
       "| 11        | 1.1645582 | 2.1944200 | 0.1346964 | \n",
       "| 12        | 1.2500835 | 2.3596040 | 0.1405630 | \n",
       "| 13        | 1.3719006 | 2.5215587 | 0.2222425 | \n",
       "| 14        | 1.4925942 | 2.6848004 | 0.3003881 | \n",
       "| 15        | 1.5725921 | 2.8375952 | 0.3075891 | \n",
       "| 16        | 1.6490359 | 2.9823272 | 0.3157445 | \n",
       "| 17        | 1.7149013 | 3.1453657 | 0.2844368 | \n",
       "| 18        | 1.8432590 | 3.3012844 | 0.3852336 | \n",
       "| 19        | 1.8721876 | 3.4490067 | 0.2953685 | \n",
       "| 20        | 1.9819118 | 3.6065065 | 0.3573171 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   K  RMSE      plus.SD   minus.SD \n",
       "1   1 0.6666252 0.9683018 0.3649486\n",
       "2   2 0.5863092 0.8959891 0.2766293\n",
       "3   3 0.4451225 0.6693854 0.2208595\n",
       "4   4 0.5242669 0.8486838 0.1998501\n",
       "5   5 0.5351558 0.9406435 0.1296680\n",
       "6   6 0.6769351 1.1712122 0.1826581\n",
       "7   7 0.7916834 1.4233227 0.1600440\n",
       "8   8 0.9174916 1.6246256 0.2103575\n",
       "9   9 0.9699439 1.8386158 0.1012721\n",
       "10 10 1.1358160 2.0308027 0.2408292\n",
       "11 11 1.1645582 2.1944200 0.1346964\n",
       "12 12 1.2500835 2.3596040 0.1405630\n",
       "13 13 1.3719006 2.5215587 0.2222425\n",
       "14 14 1.4925942 2.6848004 0.3003881\n",
       "15 15 1.5725921 2.8375952 0.3075891\n",
       "16 16 1.6490359 2.9823272 0.3157445\n",
       "17 17 1.7149013 3.1453657 0.2844368\n",
       "18 18 1.8432590 3.3012844 0.3852336\n",
       "19 19 1.8721876 3.4490067 0.2953685\n",
       "20 20 1.9819118 3.6065065 0.3573171"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# declare a matrix of the mean RMSE, RMSE + sd, RMSE - sd\n",
    "ave.errors <- data.frame('K' = 1:20, 'RMSE' = rep(0,20), 'plus.SD' = rep(0,20), 'minus.SD' = rep(0,20))\n",
    "\n",
    "for (i in 1:nrow(result)){\n",
    "    ave.errors[i, 'RMSE'] <- mean(result[i, 2:ncol(result)])\n",
    "    ave.errors[i, 'plus.SD'] <- mean(result[i, 2:ncol(result)]) + sd(result[i, 2:ncol(result)])\n",
    "    ave.errors[i, 'minus.SD'] <- mean(result[i, 2:ncol(result)]) - sd(result[i, 2:ncol(result)])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reshape for visualization\n",
    "ave.errors.m <- melt(ave.errors, id ='K')\n",
    "names(ave.errors.m ) <- c('K', 'type', 'error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAPFBMVEUAAAAAujhNTU1hnP9o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\nYxLgIhmTABfJmAT8D1FF2XAiPV6OAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the missclassification error and the errors +/- sd\n",
    "ggplot(data=ave.errors.m, aes(x=1/K, y=error, group=type, colour = type)) + \n",
    "        geom_line(aes(linetype=type, color=type)) +\n",
    "        scale_color_discrete(guide = guide_legend(title = NULL)) + theme_minimal() +\n",
    "        ggtitle(\"Average Root Mean Squared-Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2-3**\n",
    "\n",
    "Q2-3) Report the values of K that result to minimum average error and minimum standard deviation of errors based on your cross validation plot in the previous sub-question, Q2-2. \n",
    "\n",
    "**Answer**\n",
    "\n",
    "Based from the resulting errors, the optimal K would be **K = 2 or 3**, because it has both the smallest errors and standard deviation. I chose 2 *or* 3 because in some of my runs the optimal K was 2, whereas in some runs it was 3. As shown from the graph, **K = 2 or 3** is where the *bottleneck* is, which means the error and standard deviation are the smallest compared to most Ks.\n",
    "\n",
    "The model does not really present a high level of error when *considered* overfitted at **K = 1**, which means overfitting is not a risk; both the error and the standard deviation when K = 1 can still be considered low. However, major underfitting occurs when the model selected is at **K = 6 and above**, with huge root mean squared-errors and standard deviations. \n",
    "\n",
    "Looking at the graph from right to left, it really starts at a low error and standard deviation, but the gap widens after K = 6, and the error becomes very high. This means that the data is more prone to underfitted models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B. Prediction Uncertainty with Bootstrapping\n",
    "This part is the adaptation of Activity 2 from KNN classification to KNN regression. You use the bootstrapping technique to quantify the uncertainty of predictions for the KNN regressor that you implemented in Part A. \n",
    "\n",
    "#### Question 3 [Bootstrapping, 20 Marks]\n",
    "Q3-1) Modify the code in Activity 2 to handle bootstrapping for KNN regression. \n",
    "\n",
    "There's no need to modify the *boot()* function in Acitivity 2. The main modification is just to call the modified *knn()* method to do regression and *get.rmse()* to measure the error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3-2)Load Task1B_train.csv and Task1B_test.csv sets. Apply your bootstrapping for KNN regression with times = 100 (the number of subsets), size = 25 (the size of each subset), and change K=1,..,20 (the neighbourhood size). Now create a boxplot where the x-axis is K, and the y-axis is the average error (and the uncertainty around it) corresponding to each K. \n",
    "\n",
    "**Answer**\n",
    "\n",
    "This part of the assessment introduces **bootstrapping**. Bootstrapping is another way of quantifying uncertainty. It divides the dataset into N bootstraps of equal sizes, where each bootstrap contains an element that is selected from the dataset *with replacement*. This produces a \"distribution over the maximum likelihood estimates for the parameters\" (Haffari, 2017).\n",
    "\n",
    "The bootstrapping method below is taken from the Alexandria Material \"The Elements of Machine Learning\" by Haffari, G. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters:\n",
    "# original.size = size of the data being bootstrapped\n",
    "# sample.size = size (number of elements) per bootstrap\n",
    "# times = the number of bootstraps generated\n",
    "boot <- function (original.size=100, sample.size=original.size, times=100){\n",
    "    # create a matrix of bootstrapped indices\n",
    "    # per row is a bootstrap (or K)\n",
    "    # per column is an index of an element in that bootstrap\n",
    "    indx <- matrix(nrow=times, ncol=sample.size)\n",
    "    for (t in 1:times){\n",
    "        indx[t, ] <- sample(x=original.size, size=sample.size, replace = TRUE)\n",
    "    }\n",
    "    return(indx)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the boostrapping method, a new dataset will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the train and test data\n",
    "trainB.file <- read.csv(\"Task1B_train.csv\")\n",
    "testB.file <- read.csv(\"Task1B_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial exploration of the data is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in head(trainB.file): object 'trainB.file' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in head(trainB.file): object 'trainB.file' not found\nTraceback:\n",
      "1. head(trainB.file)"
     ]
    }
   ],
   "source": [
    "head(trainB.file)\n",
    "head(testB.file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new datasets have four different input variables $x_1, x_2, x_3, x_4$ and one target variable $y$. Looks like this dataset is larger with 930 observations each.\n",
    "\n",
    "Now it's time to separate the input variables (\"data\") from the target variables (\"value\"). The data will consist of columns 1 to 4, while the value contains the fifth column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>x1</th><th scope=col>x2</th><th scope=col>x3</th><th scope=col>x4</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1991.496</td><td>1628.75 </td><td>1678.1  </td><td>1772.8  </td></tr>\n",
       "\t<tr><td>1991.504</td><td>1606.51 </td><td>1678.6  </td><td>1718.0  </td></tr>\n",
       "\t<tr><td>1991.512</td><td>1618.16 </td><td>1686.6  </td><td>1723.1  </td></tr>\n",
       "\t<tr><td>1991.519</td><td>1630.75 </td><td>1682.9  </td><td>1734.5  </td></tr>\n",
       "\t<tr><td>1991.527</td><td>1635.47 </td><td>1697.5  </td><td>1754.0  </td></tr>\n",
       "\t<tr><td>1991.535</td><td>1647.84 </td><td>1723.8  </td><td>1759.8  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " x1 & x2 & x3 & x4\\\\\n",
       "\\hline\n",
       "\t 1991.496 & 1628.75  & 1678.1   & 1772.8  \\\\\n",
       "\t 1991.504 & 1606.51  & 1678.6   & 1718.0  \\\\\n",
       "\t 1991.512 & 1618.16  & 1686.6   & 1723.1  \\\\\n",
       "\t 1991.519 & 1630.75  & 1682.9   & 1734.5  \\\\\n",
       "\t 1991.527 & 1635.47  & 1697.5   & 1754.0  \\\\\n",
       "\t 1991.535 & 1647.84  & 1723.8   & 1759.8  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "x1 | x2 | x3 | x4 | \n",
       "|---|---|---|---|---|---|\n",
       "| 1991.496 | 1628.75  | 1678.1   | 1772.8   | \n",
       "| 1991.504 | 1606.51  | 1678.6   | 1718.0   | \n",
       "| 1991.512 | 1618.16  | 1686.6   | 1723.1   | \n",
       "| 1991.519 | 1630.75  | 1682.9   | 1734.5   | \n",
       "| 1991.527 | 1635.47  | 1697.5   | 1754.0   | \n",
       "| 1991.535 | 1647.84  | 1723.8   | 1759.8   | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  x1       x2      x3     x4    \n",
       "1 1991.496 1628.75 1678.1 1772.8\n",
       "2 1991.504 1606.51 1678.6 1718.0\n",
       "3 1991.512 1618.16 1686.6 1723.1\n",
       "4 1991.519 1630.75 1682.9 1734.5\n",
       "5 1991.527 1635.47 1697.5 1754.0\n",
       "6 1991.535 1647.84 1723.8 1759.8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>x1</th><th scope=col>x2</th><th scope=col>x3</th><th scope=col>x4</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1991.500</td><td>1613.63 </td><td>1688.5  </td><td>1750.5  </td></tr>\n",
       "\t<tr><td>1991.508</td><td>1621.04 </td><td>1684.1  </td><td>1708.1  </td></tr>\n",
       "\t<tr><td>1991.515</td><td>1610.61 </td><td>1671.6  </td><td>1714.3  </td></tr>\n",
       "\t<tr><td>1991.523</td><td>1640.17 </td><td>1703.6  </td><td>1757.4  </td></tr>\n",
       "\t<tr><td>1991.531</td><td>1645.89 </td><td>1716.3  </td><td>1754.3  </td></tr>\n",
       "\t<tr><td>1991.538</td><td>1638.35 </td><td>1730.5  </td><td>1755.5  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " x1 & x2 & x3 & x4\\\\\n",
       "\\hline\n",
       "\t 1991.500 & 1613.63  & 1688.5   & 1750.5  \\\\\n",
       "\t 1991.508 & 1621.04  & 1684.1   & 1708.1  \\\\\n",
       "\t 1991.515 & 1610.61  & 1671.6   & 1714.3  \\\\\n",
       "\t 1991.523 & 1640.17  & 1703.6   & 1757.4  \\\\\n",
       "\t 1991.531 & 1645.89  & 1716.3   & 1754.3  \\\\\n",
       "\t 1991.538 & 1638.35  & 1730.5   & 1755.5  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "x1 | x2 | x3 | x4 | \n",
       "|---|---|---|---|---|---|\n",
       "| 1991.500 | 1613.63  | 1688.5   | 1750.5   | \n",
       "| 1991.508 | 1621.04  | 1684.1   | 1708.1   | \n",
       "| 1991.515 | 1610.61  | 1671.6   | 1714.3   | \n",
       "| 1991.523 | 1640.17  | 1703.6   | 1757.4   | \n",
       "| 1991.531 | 1645.89  | 1716.3   | 1754.3   | \n",
       "| 1991.538 | 1638.35  | 1730.5   | 1755.5   | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  x1       x2      x3     x4    \n",
       "1 1991.500 1613.63 1688.5 1750.5\n",
       "2 1991.508 1621.04 1684.1 1708.1\n",
       "3 1991.515 1610.61 1671.6 1714.3\n",
       "4 1991.523 1640.17 1703.6 1757.4\n",
       "5 1991.531 1645.89 1716.3 1754.3\n",
       "6 1991.538 1638.35 1730.5 1755.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>2443.6</li>\n",
       "\t<li>2448.2</li>\n",
       "\t<li>2484.7</li>\n",
       "\t<li>2487.9</li>\n",
       "\t<li>2510.5</li>\n",
       "\t<li>2532.5</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 2443.6\n",
       "\\item 2448.2\n",
       "\\item 2484.7\n",
       "\\item 2487.9\n",
       "\\item 2510.5\n",
       "\\item 2532.5\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 2443.6\n",
       "2. 2448.2\n",
       "3. 2484.7\n",
       "4. 2487.9\n",
       "5. 2510.5\n",
       "6. 2532.5\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 2443.6 2448.2 2484.7 2487.9 2510.5 2532.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>2460.2</li>\n",
       "\t<li>2470.4</li>\n",
       "\t<li>2466.8</li>\n",
       "\t<li>2508.4</li>\n",
       "\t<li>2497.4</li>\n",
       "\t<li>2556.8</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 2460.2\n",
       "\\item 2470.4\n",
       "\\item 2466.8\n",
       "\\item 2508.4\n",
       "\\item 2497.4\n",
       "\\item 2556.8\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 2460.2\n",
       "2. 2470.4\n",
       "3. 2466.8\n",
       "4. 2508.4\n",
       "5. 2497.4\n",
       "6. 2556.8\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 2460.2 2470.4 2466.8 2508.4 2497.4 2556.8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# strip the fifth column\n",
    "trainB.dt <- as.data.frame(trainB.file[,-5]) \n",
    "\n",
    "# strip the fifth column\n",
    "testB.dt <- as.data.frame(testB.file[,-5])\n",
    "\n",
    "# get the fifth column\n",
    "trainB.vl <- trainB.file[,5]\n",
    "\n",
    "# get the fifth column\n",
    "testB.vl <- testB.file[,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have separated the data from training, we can now implement bootstrapping for the training data. The bootstraps will then be used to create and test the model from KNN. Note that due to the huge number of datasets, the following code will need a few minutes  to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>2845.9</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>3050.6</li>\n",
       "\t<li>3006.1</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>2348</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 2845.9\n",
       "\\item 3716.3\n",
       "\\item 2415.6\n",
       "\\item 3016.3\n",
       "\\item 2844.4\n",
       "\\item 4576.2\n",
       "\\item 3050.6\n",
       "\\item 3006.1\n",
       "\\item 3055.8\n",
       "\\item 2348\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 2845.9\n",
       "2. 3716.3\n",
       "3. 2415.6\n",
       "4. 3016.3\n",
       "5. 2844.4\n",
       "6. 4576.2\n",
       "7. 3050.6\n",
       "8. 3006.1\n",
       "9. 3055.8\n",
       "10. 2348\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 2845.9 3716.3 2415.6 3016.3 2844.4 4576.2 3050.6 3006.1 3055.8 2348.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainB.vl[indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'double'"
      ],
      "text/latex": [
       "'double'"
      ],
      "text/markdown": [
       "'double'"
      ],
      "text/plain": [
       "[1] \"double\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "typeof(trainB.vl[indx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2348</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2415.6</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2845.9</li>\n",
       "\t<li>2845.9</li>\n",
       "\t<li>2844.4</li>\n",
       "\t<li>2845.9</li>\n",
       "\t<li>2845.9</li>\n",
       "\t<li>2845.9</li>\n",
       "\t<li>2845.9</li>\n",
       "\t<li>2845.9</li>\n",
       "\t<li>2845.9</li>\n",
       "\t<li>2845.9</li>\n",
       "\t<li>2845.9</li>\n",
       "\t<li>2845.9</li>\n",
       "\t<li>3006.1</li>\n",
       "\t<li>3006.1</li>\n",
       "\t<li>3006.1</li>\n",
       "\t<li>3006.1</li>\n",
       "\t<li>3006.1</li>\n",
       "\t<li>3006.1</li>\n",
       "\t<li>3006.1</li>\n",
       "\t<li>3006.1</li>\n",
       "\t<li>3006.1</li>\n",
       "\t<li>3006.1</li>\n",
       "\t<li>3006.1</li>\n",
       "\t<li>3006.1</li>\n",
       "\t<li>3006.1</li>\n",
       "\t<li>3006.1</li>\n",
       "\t<li>3006.1</li>\n",
       "\t<li>3006.1</li>\n",
       "\t<li>3006.1</li>\n",
       "\t<li>3006.1</li>\n",
       "\t<li>3006.1</li>\n",
       "\t<li>3006.1</li>\n",
       "\t<li>3006.1</li>\n",
       "\t<li>3006.1</li>\n",
       "\t<li>3006.1</li>\n",
       "\t<li>3006.1</li>\n",
       "\t<li>3006.1</li>\n",
       "\t<li>3006.1</li>\n",
       "\t<li>3006.1</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3050.6</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3050.6</li>\n",
       "\t<li>3050.6</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3050.6</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3050.6</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3050.6</li>\n",
       "\t<li>3050.6</li>\n",
       "\t<li>3050.6</li>\n",
       "\t<li>3050.6</li>\n",
       "\t<li>3050.6</li>\n",
       "\t<li>3050.6</li>\n",
       "\t<li>3050.6</li>\n",
       "\t<li>3050.6</li>\n",
       "\t<li>3050.6</li>\n",
       "\t<li>3050.6</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3055.8</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3016.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>3716.3</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "\t<li>4576.2</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2415.6\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2415.6\n",
       "\\item 2348\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2415.6\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2415.6\n",
       "\\item 2348\n",
       "\\item 2415.6\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2348\n",
       "\\item 2348\n",
       "\\item 2415.6\n",
       "\\item 2415.6\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2844.4\n",
       "\\item 2845.9\n",
       "\\item 2845.9\n",
       "\\item 2844.4\n",
       "\\item 2845.9\n",
       "\\item 2845.9\n",
       "\\item 2845.9\n",
       "\\item 2845.9\n",
       "\\item 2845.9\n",
       "\\item 2845.9\n",
       "\\item 2845.9\n",
       "\\item 2845.9\n",
       "\\item 2845.9\n",
       "\\item 3006.1\n",
       "\\item 3006.1\n",
       "\\item 3006.1\n",
       "\\item 3006.1\n",
       "\\item 3006.1\n",
       "\\item 3006.1\n",
       "\\item 3006.1\n",
       "\\item 3006.1\n",
       "\\item 3006.1\n",
       "\\item 3006.1\n",
       "\\item 3006.1\n",
       "\\item 3006.1\n",
       "\\item 3006.1\n",
       "\\item 3006.1\n",
       "\\item 3006.1\n",
       "\\item 3006.1\n",
       "\\item 3006.1\n",
       "\\item 3006.1\n",
       "\\item 3006.1\n",
       "\\item 3006.1\n",
       "\\item 3006.1\n",
       "\\item 3006.1\n",
       "\\item 3006.1\n",
       "\\item 3006.1\n",
       "\\item 3006.1\n",
       "\\item 3006.1\n",
       "\\item 3006.1\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3716.3\n",
       "\\item 3016.3\n",
       "\\item 3716.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3055.8\n",
       "\\item 3016.3\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3050.6\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3050.6\n",
       "\\item 3050.6\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3050.6\n",
       "\\item 3055.8\n",
       "\\item 3050.6\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3050.6\n",
       "\\item 3050.6\n",
       "\\item 3050.6\n",
       "\\item 3050.6\n",
       "\\item 3050.6\n",
       "\\item 3050.6\n",
       "\\item 3050.6\n",
       "\\item 3050.6\n",
       "\\item 3050.6\n",
       "\\item 3050.6\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3055.8\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3016.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3016.3\n",
       "\\item 3716.3\n",
       "\\item 3016.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 3716.3\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\item 4576.2\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 2348\n",
       "2. 2348\n",
       "3. 2348\n",
       "4. 2348\n",
       "5. 2348\n",
       "6. 2348\n",
       "7. 2348\n",
       "8. 2348\n",
       "9. 2348\n",
       "10. 2348\n",
       "11. 2348\n",
       "12. 2348\n",
       "13. 2348\n",
       "14. 2348\n",
       "15. 2348\n",
       "16. 2348\n",
       "17. 2415.6\n",
       "18. 2348\n",
       "19. 2348\n",
       "20. 2348\n",
       "21. 2348\n",
       "22. 2415.6\n",
       "23. 2415.6\n",
       "24. 2415.6\n",
       "25. 2348\n",
       "26. 2348\n",
       "27. 2348\n",
       "28. 2348\n",
       "29. 2348\n",
       "30. 2348\n",
       "31. 2348\n",
       "32. 2348\n",
       "33. 2348\n",
       "34. 2348\n",
       "35. 2348\n",
       "36. 2348\n",
       "37. 2348\n",
       "38. 2348\n",
       "39. 2348\n",
       "40. 2348\n",
       "41. 2348\n",
       "42. 2348\n",
       "43. 2348\n",
       "44. 2348\n",
       "45. 2348\n",
       "46. 2348\n",
       "47. 2348\n",
       "48. 2348\n",
       "49. 2348\n",
       "50. 2348\n",
       "51. 2348\n",
       "52. 2348\n",
       "53. 2348\n",
       "54. 2348\n",
       "55. 2348\n",
       "56. 2348\n",
       "57. 2348\n",
       "58. 2348\n",
       "59. 2348\n",
       "60. 2348\n",
       "61. 2348\n",
       "62. 2348\n",
       "63. 2348\n",
       "64. 2348\n",
       "65. 2348\n",
       "66. 2348\n",
       "67. 2348\n",
       "68. 2348\n",
       "69. 2348\n",
       "70. 2348\n",
       "71. 2348\n",
       "72. 2415.6\n",
       "73. 2415.6\n",
       "74. 2415.6\n",
       "75. 2415.6\n",
       "76. 2415.6\n",
       "77. 2415.6\n",
       "78. 2415.6\n",
       "79. 2415.6\n",
       "80. 2415.6\n",
       "81. 2415.6\n",
       "82. 2415.6\n",
       "83. 2415.6\n",
       "84. 2415.6\n",
       "85. 2415.6\n",
       "86. 2415.6\n",
       "87. 2415.6\n",
       "88. 2415.6\n",
       "89. 2415.6\n",
       "90. 2415.6\n",
       "91. 2415.6\n",
       "92. 2415.6\n",
       "93. 2415.6\n",
       "94. 2415.6\n",
       "95. 2415.6\n",
       "96. 2415.6\n",
       "97. 2415.6\n",
       "98. 2415.6\n",
       "99. 2415.6\n",
       "100. 2415.6\n",
       "101. 2415.6\n",
       "102. 2415.6\n",
       "103. 2415.6\n",
       "104. 2415.6\n",
       "105. 2415.6\n",
       "106. 2415.6\n",
       "107. 2415.6\n",
       "108. 2415.6\n",
       "109. 2415.6\n",
       "110. 2415.6\n",
       "111. 2415.6\n",
       "112. 2415.6\n",
       "113. 2415.6\n",
       "114. 2415.6\n",
       "115. 2415.6\n",
       "116. 2415.6\n",
       "117. 2415.6\n",
       "118. 2415.6\n",
       "119. 2415.6\n",
       "120. 2415.6\n",
       "121. 2415.6\n",
       "122. 2415.6\n",
       "123. 2415.6\n",
       "124. 2415.6\n",
       "125. 2415.6\n",
       "126. 2415.6\n",
       "127. 2415.6\n",
       "128. 2415.6\n",
       "129. 2415.6\n",
       "130. 2415.6\n",
       "131. 2415.6\n",
       "132. 2415.6\n",
       "133. 2415.6\n",
       "134. 2415.6\n",
       "135. 2415.6\n",
       "136. 2415.6\n",
       "137. 2415.6\n",
       "138. 2415.6\n",
       "139. 2348\n",
       "140. 2348\n",
       "141. 2348\n",
       "142. 2415.6\n",
       "143. 2348\n",
       "144. 2415.6\n",
       "145. 2415.6\n",
       "146. 2348\n",
       "147. 2348\n",
       "148. 2348\n",
       "149. 2348\n",
       "150. 2348\n",
       "151. 2348\n",
       "152. 2348\n",
       "153. 2348\n",
       "154. 2348\n",
       "155. 2348\n",
       "156. 2348\n",
       "157. 2348\n",
       "158. 2415.6\n",
       "159. 2415.6\n",
       "160. 2415.6\n",
       "161. 2415.6\n",
       "162. 2415.6\n",
       "163. 2348\n",
       "164. 2348\n",
       "165. 2348\n",
       "166. 2348\n",
       "167. 2348\n",
       "168. 2348\n",
       "169. 2348\n",
       "170. 2348\n",
       "171. 2348\n",
       "172. 2348\n",
       "173. 2415.6\n",
       "174. 2348\n",
       "175. 2348\n",
       "176. 2348\n",
       "177. 2348\n",
       "178. 2415.6\n",
       "179. 2348\n",
       "180. 2415.6\n",
       "181. 2348\n",
       "182. 2348\n",
       "183. 2348\n",
       "184. 2348\n",
       "185. 2348\n",
       "186. 2415.6\n",
       "187. 2415.6\n",
       "188. 2415.6\n",
       "189. 2415.6\n",
       "190. 2348\n",
       "191. 2348\n",
       "192. 2415.6\n",
       "193. 2415.6\n",
       "194. 2844.4\n",
       "195. 2844.4\n",
       "196. 2844.4\n",
       "197. 2844.4\n",
       "198. 2844.4\n",
       "199. 2844.4\n",
       "200. 2844.4\n",
       "201. 2844.4\n",
       "202. 2844.4\n",
       "203. 2844.4\n",
       "204. 2844.4\n",
       "205. 2844.4\n",
       "206. 2844.4\n",
       "207. 2844.4\n",
       "208. 2844.4\n",
       "209. 2844.4\n",
       "210. 2844.4\n",
       "211. 2844.4\n",
       "212. 2844.4\n",
       "213. 2844.4\n",
       "214. 2844.4\n",
       "215. 2844.4\n",
       "216. 2844.4\n",
       "217. 2844.4\n",
       "218. 2844.4\n",
       "219. 2844.4\n",
       "220. 2844.4\n",
       "221. 2844.4\n",
       "222. 2844.4\n",
       "223. 2844.4\n",
       "224. 2844.4\n",
       "225. 2844.4\n",
       "226. 2844.4\n",
       "227. 2844.4\n",
       "228. 2844.4\n",
       "229. 2844.4\n",
       "230. 2844.4\n",
       "231. 2844.4\n",
       "232. 2844.4\n",
       "233. 2844.4\n",
       "234. 2844.4\n",
       "235. 2844.4\n",
       "236. 2844.4\n",
       "237. 2844.4\n",
       "238. 2844.4\n",
       "239. 2844.4\n",
       "240. 2844.4\n",
       "241. 2844.4\n",
       "242. 2844.4\n",
       "243. 2844.4\n",
       "244. 2844.4\n",
       "245. 2844.4\n",
       "246. 2844.4\n",
       "247. 2844.4\n",
       "248. 2844.4\n",
       "249. 2844.4\n",
       "250. 2844.4\n",
       "251. 2844.4\n",
       "252. 2844.4\n",
       "253. 2844.4\n",
       "254. 2844.4\n",
       "255. 2844.4\n",
       "256. 2844.4\n",
       "257. 2844.4\n",
       "258. 2844.4\n",
       "259. 2844.4\n",
       "260. 2844.4\n",
       "261. 2845.9\n",
       "262. 2845.9\n",
       "263. 2844.4\n",
       "264. 2845.9\n",
       "265. 2845.9\n",
       "266. 2845.9\n",
       "267. 2845.9\n",
       "268. 2845.9\n",
       "269. 2845.9\n",
       "270. 2845.9\n",
       "271. 2845.9\n",
       "272. 2845.9\n",
       "273. 3006.1\n",
       "274. 3006.1\n",
       "275. 3006.1\n",
       "276. 3006.1\n",
       "277. 3006.1\n",
       "278. 3006.1\n",
       "279. 3006.1\n",
       "280. 3006.1\n",
       "281. 3006.1\n",
       "282. 3006.1\n",
       "283. 3006.1\n",
       "284. 3006.1\n",
       "285. 3006.1\n",
       "286. 3006.1\n",
       "287. 3006.1\n",
       "288. 3006.1\n",
       "289. 3006.1\n",
       "290. 3006.1\n",
       "291. 3006.1\n",
       "292. 3006.1\n",
       "293. 3006.1\n",
       "294. 3006.1\n",
       "295. 3006.1\n",
       "296. 3006.1\n",
       "297. 3006.1\n",
       "298. 3006.1\n",
       "299. 3006.1\n",
       "300. 3016.3\n",
       "301. 3016.3\n",
       "302. 3016.3\n",
       "303. 3016.3\n",
       "304. 3016.3\n",
       "305. 3016.3\n",
       "306. 3016.3\n",
       "307. 3016.3\n",
       "308. 3016.3\n",
       "309. 3016.3\n",
       "310. 3016.3\n",
       "311. 3016.3\n",
       "312. 3016.3\n",
       "313. 3016.3\n",
       "314. 3016.3\n",
       "315. 3016.3\n",
       "316. 3016.3\n",
       "317. 3016.3\n",
       "318. 3016.3\n",
       "319. 3016.3\n",
       "320. 3016.3\n",
       "321. 3016.3\n",
       "322. 3016.3\n",
       "323. 3016.3\n",
       "324. 3016.3\n",
       "325. 3016.3\n",
       "326. 3016.3\n",
       "327. 3016.3\n",
       "328. 3716.3\n",
       "329. 3016.3\n",
       "330. 3716.3\n",
       "331. 3016.3\n",
       "332. 3016.3\n",
       "333. 3016.3\n",
       "334. 3016.3\n",
       "335. 3016.3\n",
       "336. 3016.3\n",
       "337. 3016.3\n",
       "338. 3716.3\n",
       "339. 3716.3\n",
       "340. 3716.3\n",
       "341. 3016.3\n",
       "342. 3016.3\n",
       "343. 3016.3\n",
       "344. 3016.3\n",
       "345. 3016.3\n",
       "346. 3016.3\n",
       "347. 3016.3\n",
       "348. 3016.3\n",
       "349. 3016.3\n",
       "350. 3016.3\n",
       "351. 3016.3\n",
       "352. 3016.3\n",
       "353. 3016.3\n",
       "354. 3016.3\n",
       "355. 3016.3\n",
       "356. 3016.3\n",
       "357. 3016.3\n",
       "358. 3016.3\n",
       "359. 3016.3\n",
       "360. 3016.3\n",
       "361. 3016.3\n",
       "362. 3016.3\n",
       "363. 3016.3\n",
       "364. 3016.3\n",
       "365. 3016.3\n",
       "366. 3016.3\n",
       "367. 3016.3\n",
       "368. 3016.3\n",
       "369. 3016.3\n",
       "370. 3016.3\n",
       "371. 3016.3\n",
       "372. 3016.3\n",
       "373. 3016.3\n",
       "374. 3016.3\n",
       "375. 3016.3\n",
       "376. 3016.3\n",
       "377. 3016.3\n",
       "378. 3016.3\n",
       "379. 3016.3\n",
       "380. 3016.3\n",
       "381. 3016.3\n",
       "382. 3016.3\n",
       "383. 3016.3\n",
       "384. 3016.3\n",
       "385. 3016.3\n",
       "386. 3016.3\n",
       "387. 3016.3\n",
       "388. 3055.8\n",
       "389. 3055.8\n",
       "390. 3055.8\n",
       "391. 3055.8\n",
       "392. 3055.8\n",
       "393. 3055.8\n",
       "394. 3055.8\n",
       "395. 3055.8\n",
       "396. 3055.8\n",
       "397. 3055.8\n",
       "398. 3055.8\n",
       "399. 3016.3\n",
       "400. 3016.3\n",
       "401. 3016.3\n",
       "402. 3016.3\n",
       "403. 3016.3\n",
       "404. 3016.3\n",
       "405. 3016.3\n",
       "406. 3016.3\n",
       "407. 3016.3\n",
       "408. 3055.8\n",
       "409. 3016.3\n",
       "410. 3055.8\n",
       "411. 3055.8\n",
       "412. 3055.8\n",
       "413. 3016.3\n",
       "414. 3016.3\n",
       "415. 3016.3\n",
       "416. 3016.3\n",
       "417. 3016.3\n",
       "418. 3016.3\n",
       "419. 3055.8\n",
       "420. 3055.8\n",
       "421. 3055.8\n",
       "422. 3055.8\n",
       "423. 3055.8\n",
       "424. 3055.8\n",
       "425. 3055.8\n",
       "426. 3055.8\n",
       "427. 3050.6\n",
       "428. 3055.8\n",
       "429. 3055.8\n",
       "430. 3055.8\n",
       "431. 3055.8\n",
       "432. 3055.8\n",
       "433. 3050.6\n",
       "434. 3050.6\n",
       "435. 3055.8\n",
       "436. 3055.8\n",
       "437. 3055.8\n",
       "438. 3055.8\n",
       "439. 3055.8\n",
       "440. 3055.8\n",
       "441. 3055.8\n",
       "442. 3055.8\n",
       "443. 3055.8\n",
       "444. 3055.8\n",
       "445. 3055.8\n",
       "446. 3055.8\n",
       "447. 3055.8\n",
       "448. 3055.8\n",
       "449. 3055.8\n",
       "450. 3055.8\n",
       "451. 3055.8\n",
       "452. 3055.8\n",
       "453. 3055.8\n",
       "454. 3055.8\n",
       "455. 3016.3\n",
       "456. 3016.3\n",
       "457. 3055.8\n",
       "458. 3055.8\n",
       "459. 3055.8\n",
       "460. 3055.8\n",
       "461. 3055.8\n",
       "462. 3055.8\n",
       "463. 3055.8\n",
       "464. 3055.8\n",
       "465. 3055.8\n",
       "466. 3050.6\n",
       "467. 3055.8\n",
       "468. 3050.6\n",
       "469. 3055.8\n",
       "470. 3055.8\n",
       "471. 3055.8\n",
       "472. 3055.8\n",
       "473. 3055.8\n",
       "474. 3055.8\n",
       "475. 3055.8\n",
       "476. 3055.8\n",
       "477. 3055.8\n",
       "478. 3055.8\n",
       "479. 3055.8\n",
       "480. 3055.8\n",
       "481. 3050.6\n",
       "482. 3050.6\n",
       "483. 3050.6\n",
       "484. 3050.6\n",
       "485. 3050.6\n",
       "486. 3050.6\n",
       "487. 3050.6\n",
       "488. 3050.6\n",
       "489. 3050.6\n",
       "490. 3050.6\n",
       "491. 3055.8\n",
       "492. 3055.8\n",
       "493. 3055.8\n",
       "494. 3055.8\n",
       "495. 3055.8\n",
       "496. 3055.8\n",
       "497. 3055.8\n",
       "498. 3055.8\n",
       "499. 3055.8\n",
       "500. 3055.8\n",
       "501. 3055.8\n",
       "502. 3055.8\n",
       "503. 3055.8\n",
       "504. 3016.3\n",
       "505. 3016.3\n",
       "506. 3016.3\n",
       "507. 3016.3\n",
       "508. 3016.3\n",
       "509. 3016.3\n",
       "510. 3016.3\n",
       "511. 3016.3\n",
       "512. 3016.3\n",
       "513. 3016.3\n",
       "514. 3016.3\n",
       "515. 3016.3\n",
       "516. 3016.3\n",
       "517. 3016.3\n",
       "518. 3016.3\n",
       "519. 3016.3\n",
       "520. 3016.3\n",
       "521. 3016.3\n",
       "522. 3016.3\n",
       "523. 3016.3\n",
       "524. 3016.3\n",
       "525. 3016.3\n",
       "526. 3016.3\n",
       "527. 3016.3\n",
       "528. 3016.3\n",
       "529. 3016.3\n",
       "530. 3016.3\n",
       "531. 3016.3\n",
       "532. 3016.3\n",
       "533. 3016.3\n",
       "534. 3016.3\n",
       "535. 3016.3\n",
       "536. 3016.3\n",
       "537. 3016.3\n",
       "538. 3016.3\n",
       "539. 3016.3\n",
       "540. 3016.3\n",
       "541. 3016.3\n",
       "542. 3016.3\n",
       "543. 3016.3\n",
       "544. 3016.3\n",
       "545. 3016.3\n",
       "546. 3016.3\n",
       "547. 3716.3\n",
       "548. 3716.3\n",
       "549. 3716.3\n",
       "550. 3716.3\n",
       "551. 3716.3\n",
       "552. 3716.3\n",
       "553. 3016.3\n",
       "554. 3016.3\n",
       "555. 3016.3\n",
       "556. 3716.3\n",
       "557. 3716.3\n",
       "558. 3716.3\n",
       "559. 3716.3\n",
       "560. 3716.3\n",
       "561. 3716.3\n",
       "562. 3716.3\n",
       "563. 3016.3\n",
       "564. 3716.3\n",
       "565. 3016.3\n",
       "566. 3716.3\n",
       "567. 3716.3\n",
       "568. 3716.3\n",
       "569. 3716.3\n",
       "570. 3716.3\n",
       "571. 3716.3\n",
       "572. 3716.3\n",
       "573. 3716.3\n",
       "574. 3716.3\n",
       "575. 3716.3\n",
       "576. 3716.3\n",
       "577. 3716.3\n",
       "578. 3716.3\n",
       "579. 3716.3\n",
       "580. 3716.3\n",
       "581. 3716.3\n",
       "582. 3716.3\n",
       "583. 3716.3\n",
       "584. 3716.3\n",
       "585. 3716.3\n",
       "586. 3716.3\n",
       "587. 3716.3\n",
       "588. 3716.3\n",
       "589. 3716.3\n",
       "590. 3716.3\n",
       "591. 3716.3\n",
       "592. 3716.3\n",
       "593. 3716.3\n",
       "594. 3716.3\n",
       "595. 3716.3\n",
       "596. 3716.3\n",
       "597. 3716.3\n",
       "598. 3716.3\n",
       "599. 3716.3\n",
       "600. 3716.3\n",
       "601. 3716.3\n",
       "602. 3716.3\n",
       "603. 3716.3\n",
       "604. 3716.3\n",
       "605. 3716.3\n",
       "606. 3716.3\n",
       "607. 3716.3\n",
       "608. 3716.3\n",
       "609. 3716.3\n",
       "610. 3716.3\n",
       "611. 3716.3\n",
       "612. 3716.3\n",
       "613. 3716.3\n",
       "614. 3716.3\n",
       "615. 3716.3\n",
       "616. 3716.3\n",
       "617. 3716.3\n",
       "618. 3716.3\n",
       "619. 3716.3\n",
       "620. 3716.3\n",
       "621. 3716.3\n",
       "622. 3716.3\n",
       "623. 3716.3\n",
       "624. 3716.3\n",
       "625. 3716.3\n",
       "626. 3716.3\n",
       "627. 3716.3\n",
       "628. 3716.3\n",
       "629. 3716.3\n",
       "630. 3716.3\n",
       "631. 3716.3\n",
       "632. 3716.3\n",
       "633. 3716.3\n",
       "634. 3716.3\n",
       "635. 3716.3\n",
       "636. 3716.3\n",
       "637. 3716.3\n",
       "638. 3716.3\n",
       "639. 3716.3\n",
       "640. 3716.3\n",
       "641. 3716.3\n",
       "642. 3716.3\n",
       "643. 3716.3\n",
       "644. 3716.3\n",
       "645. 3716.3\n",
       "646. 3716.3\n",
       "647. 3716.3\n",
       "648. 3716.3\n",
       "649. 3716.3\n",
       "650. 3716.3\n",
       "651. 3716.3\n",
       "652. 3716.3\n",
       "653. 3716.3\n",
       "654. 3716.3\n",
       "655. 3716.3\n",
       "656. 3716.3\n",
       "657. 3716.3\n",
       "658. 3716.3\n",
       "659. 3716.3\n",
       "660. 3716.3\n",
       "661. 3716.3\n",
       "662. 3716.3\n",
       "663. 3716.3\n",
       "664. 3716.3\n",
       "665. 3716.3\n",
       "666. 3716.3\n",
       "667. 3716.3\n",
       "668. 3716.3\n",
       "669. 3716.3\n",
       "670. 3716.3\n",
       "671. 3716.3\n",
       "672. 3716.3\n",
       "673. 3716.3\n",
       "674. 3716.3\n",
       "675. 3716.3\n",
       "676. 3716.3\n",
       "677. 3716.3\n",
       "678. 3716.3\n",
       "679. 3716.3\n",
       "680. 3716.3\n",
       "681. 3716.3\n",
       "682. 3716.3\n",
       "683. 3716.3\n",
       "684. 3716.3\n",
       "685. 3716.3\n",
       "686. 3716.3\n",
       "687. 3716.3\n",
       "688. 3716.3\n",
       "689. 3716.3\n",
       "690. 3716.3\n",
       "691. 3716.3\n",
       "692. 3716.3\n",
       "693. 3716.3\n",
       "694. 3716.3\n",
       "695. 3716.3\n",
       "696. 3716.3\n",
       "697. 3716.3\n",
       "698. 3716.3\n",
       "699. 3716.3\n",
       "700. 3716.3\n",
       "701. 3716.3\n",
       "702. 3716.3\n",
       "703. 3716.3\n",
       "704. 3716.3\n",
       "705. 3716.3\n",
       "706. 3716.3\n",
       "707. 3716.3\n",
       "708. 3716.3\n",
       "709. 3716.3\n",
       "710. 3716.3\n",
       "711. 3716.3\n",
       "712. 3716.3\n",
       "713. 3716.3\n",
       "714. 3716.3\n",
       "715. 3716.3\n",
       "716. 3716.3\n",
       "717. 3716.3\n",
       "718. 3716.3\n",
       "719. 3716.3\n",
       "720. 3716.3\n",
       "721. 3716.3\n",
       "722. 3716.3\n",
       "723. 3716.3\n",
       "724. 3716.3\n",
       "725. 3716.3\n",
       "726. 3716.3\n",
       "727. 3716.3\n",
       "728. 3716.3\n",
       "729. 3716.3\n",
       "730. 4576.2\n",
       "731. 4576.2\n",
       "732. 4576.2\n",
       "733. 4576.2\n",
       "734. 4576.2\n",
       "735. 4576.2\n",
       "736. 4576.2\n",
       "737. 4576.2\n",
       "738. 4576.2\n",
       "739. 4576.2\n",
       "740. 4576.2\n",
       "741. 4576.2\n",
       "742. 4576.2\n",
       "743. 4576.2\n",
       "744. 4576.2\n",
       "745. 4576.2\n",
       "746. 4576.2\n",
       "747. 4576.2\n",
       "748. 4576.2\n",
       "749. 4576.2\n",
       "750. 4576.2\n",
       "751. 4576.2\n",
       "752. 4576.2\n",
       "753. 4576.2\n",
       "754. 4576.2\n",
       "755. 4576.2\n",
       "756. 4576.2\n",
       "757. 4576.2\n",
       "758. 4576.2\n",
       "759. 4576.2\n",
       "760. 4576.2\n",
       "761. 4576.2\n",
       "762. 4576.2\n",
       "763. 4576.2\n",
       "764. 4576.2\n",
       "765. 4576.2\n",
       "766. 4576.2\n",
       "767. 4576.2\n",
       "768. 4576.2\n",
       "769. 4576.2\n",
       "770. 4576.2\n",
       "771. 4576.2\n",
       "772. 4576.2\n",
       "773. 4576.2\n",
       "774. 4576.2\n",
       "775. 4576.2\n",
       "776. 4576.2\n",
       "777. 4576.2\n",
       "778. 4576.2\n",
       "779. 4576.2\n",
       "780. 4576.2\n",
       "781. 4576.2\n",
       "782. 4576.2\n",
       "783. 4576.2\n",
       "784. 4576.2\n",
       "785. 4576.2\n",
       "786. 4576.2\n",
       "787. 4576.2\n",
       "788. 4576.2\n",
       "789. 4576.2\n",
       "790. 4576.2\n",
       "791. 4576.2\n",
       "792. 4576.2\n",
       "793. 4576.2\n",
       "794. 4576.2\n",
       "795. 4576.2\n",
       "796. 4576.2\n",
       "797. 4576.2\n",
       "798. 4576.2\n",
       "799. 4576.2\n",
       "800. 4576.2\n",
       "801. 4576.2\n",
       "802. 4576.2\n",
       "803. 4576.2\n",
       "804. 4576.2\n",
       "805. 4576.2\n",
       "806. 4576.2\n",
       "807. 4576.2\n",
       "808. 4576.2\n",
       "809. 4576.2\n",
       "810. 4576.2\n",
       "811. 4576.2\n",
       "812. 4576.2\n",
       "813. 4576.2\n",
       "814. 4576.2\n",
       "815. 4576.2\n",
       "816. 4576.2\n",
       "817. 4576.2\n",
       "818. 4576.2\n",
       "819. 4576.2\n",
       "820. 4576.2\n",
       "821. 4576.2\n",
       "822. 4576.2\n",
       "823. 4576.2\n",
       "824. 4576.2\n",
       "825. 4576.2\n",
       "826. 4576.2\n",
       "827. 4576.2\n",
       "828. 4576.2\n",
       "829. 4576.2\n",
       "830. 4576.2\n",
       "831. 4576.2\n",
       "832. 4576.2\n",
       "833. 4576.2\n",
       "834. 4576.2\n",
       "835. 4576.2\n",
       "836. 4576.2\n",
       "837. 4576.2\n",
       "838. 4576.2\n",
       "839. 4576.2\n",
       "840. 4576.2\n",
       "841. 4576.2\n",
       "842. 4576.2\n",
       "843. 4576.2\n",
       "844. 4576.2\n",
       "845. 4576.2\n",
       "846. 4576.2\n",
       "847. 4576.2\n",
       "848. 4576.2\n",
       "849. 4576.2\n",
       "850. 4576.2\n",
       "851. 4576.2\n",
       "852. 4576.2\n",
       "853. 4576.2\n",
       "854. 4576.2\n",
       "855. 4576.2\n",
       "856. 4576.2\n",
       "857. 4576.2\n",
       "858. 4576.2\n",
       "859. 4576.2\n",
       "860. 4576.2\n",
       "861. 4576.2\n",
       "862. 4576.2\n",
       "863. 4576.2\n",
       "864. 4576.2\n",
       "865. 4576.2\n",
       "866. 4576.2\n",
       "867. 4576.2\n",
       "868. 4576.2\n",
       "869. 4576.2\n",
       "870. 4576.2\n",
       "871. 4576.2\n",
       "872. 4576.2\n",
       "873. 4576.2\n",
       "874. 4576.2\n",
       "875. 4576.2\n",
       "876. 4576.2\n",
       "877. 4576.2\n",
       "878. 4576.2\n",
       "879. 4576.2\n",
       "880. 4576.2\n",
       "881. 4576.2\n",
       "882. 4576.2\n",
       "883. 4576.2\n",
       "884. 4576.2\n",
       "885. 4576.2\n",
       "886. 4576.2\n",
       "887. 4576.2\n",
       "888. 4576.2\n",
       "889. 4576.2\n",
       "890. 4576.2\n",
       "891. 4576.2\n",
       "892. 4576.2\n",
       "893. 4576.2\n",
       "894. 4576.2\n",
       "895. 4576.2\n",
       "896. 4576.2\n",
       "897. 4576.2\n",
       "898. 4576.2\n",
       "899. 4576.2\n",
       "900. 4576.2\n",
       "901. 4576.2\n",
       "902. 4576.2\n",
       "903. 4576.2\n",
       "904. 4576.2\n",
       "905. 4576.2\n",
       "906. 4576.2\n",
       "907. 4576.2\n",
       "908. 4576.2\n",
       "909. 4576.2\n",
       "910. 4576.2\n",
       "911. 4576.2\n",
       "912. 4576.2\n",
       "913. 4576.2\n",
       "914. 4576.2\n",
       "915. 4576.2\n",
       "916. 4576.2\n",
       "917. 4576.2\n",
       "918. 4576.2\n",
       "919. 4576.2\n",
       "920. 4576.2\n",
       "921. 4576.2\n",
       "922. 4576.2\n",
       "923. 4576.2\n",
       "924. 4576.2\n",
       "925. 4576.2\n",
       "926. 4576.2\n",
       "927. 4576.2\n",
       "928. 4576.2\n",
       "929. 4576.2\n",
       "930. 4576.2\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  [1] 2348.0 2348.0 2348.0 2348.0 2348.0 2348.0 2348.0 2348.0 2348.0 2348.0\n",
       " [11] 2348.0 2348.0 2348.0 2348.0 2348.0 2348.0 2415.6 2348.0 2348.0 2348.0\n",
       " [21] 2348.0 2415.6 2415.6 2415.6 2348.0 2348.0 2348.0 2348.0 2348.0 2348.0\n",
       " [31] 2348.0 2348.0 2348.0 2348.0 2348.0 2348.0 2348.0 2348.0 2348.0 2348.0\n",
       " [41] 2348.0 2348.0 2348.0 2348.0 2348.0 2348.0 2348.0 2348.0 2348.0 2348.0\n",
       " [51] 2348.0 2348.0 2348.0 2348.0 2348.0 2348.0 2348.0 2348.0 2348.0 2348.0\n",
       " [61] 2348.0 2348.0 2348.0 2348.0 2348.0 2348.0 2348.0 2348.0 2348.0 2348.0\n",
       " [71] 2348.0 2415.6 2415.6 2415.6 2415.6 2415.6 2415.6 2415.6 2415.6 2415.6\n",
       " [81] 2415.6 2415.6 2415.6 2415.6 2415.6 2415.6 2415.6 2415.6 2415.6 2415.6\n",
       " [91] 2415.6 2415.6 2415.6 2415.6 2415.6 2415.6 2415.6 2415.6 2415.6 2415.6\n",
       "[101] 2415.6 2415.6 2415.6 2415.6 2415.6 2415.6 2415.6 2415.6 2415.6 2415.6\n",
       "[111] 2415.6 2415.6 2415.6 2415.6 2415.6 2415.6 2415.6 2415.6 2415.6 2415.6\n",
       "[121] 2415.6 2415.6 2415.6 2415.6 2415.6 2415.6 2415.6 2415.6 2415.6 2415.6\n",
       "[131] 2415.6 2415.6 2415.6 2415.6 2415.6 2415.6 2415.6 2415.6 2348.0 2348.0\n",
       "[141] 2348.0 2415.6 2348.0 2415.6 2415.6 2348.0 2348.0 2348.0 2348.0 2348.0\n",
       "[151] 2348.0 2348.0 2348.0 2348.0 2348.0 2348.0 2348.0 2415.6 2415.6 2415.6\n",
       "[161] 2415.6 2415.6 2348.0 2348.0 2348.0 2348.0 2348.0 2348.0 2348.0 2348.0\n",
       "[171] 2348.0 2348.0 2415.6 2348.0 2348.0 2348.0 2348.0 2415.6 2348.0 2415.6\n",
       "[181] 2348.0 2348.0 2348.0 2348.0 2348.0 2415.6 2415.6 2415.6 2415.6 2348.0\n",
       "[191] 2348.0 2415.6 2415.6 2844.4 2844.4 2844.4 2844.4 2844.4 2844.4 2844.4\n",
       "[201] 2844.4 2844.4 2844.4 2844.4 2844.4 2844.4 2844.4 2844.4 2844.4 2844.4\n",
       "[211] 2844.4 2844.4 2844.4 2844.4 2844.4 2844.4 2844.4 2844.4 2844.4 2844.4\n",
       "[221] 2844.4 2844.4 2844.4 2844.4 2844.4 2844.4 2844.4 2844.4 2844.4 2844.4\n",
       "[231] 2844.4 2844.4 2844.4 2844.4 2844.4 2844.4 2844.4 2844.4 2844.4 2844.4\n",
       "[241] 2844.4 2844.4 2844.4 2844.4 2844.4 2844.4 2844.4 2844.4 2844.4 2844.4\n",
       "[251] 2844.4 2844.4 2844.4 2844.4 2844.4 2844.4 2844.4 2844.4 2844.4 2844.4\n",
       "[261] 2845.9 2845.9 2844.4 2845.9 2845.9 2845.9 2845.9 2845.9 2845.9 2845.9\n",
       "[271] 2845.9 2845.9 3006.1 3006.1 3006.1 3006.1 3006.1 3006.1 3006.1 3006.1\n",
       "[281] 3006.1 3006.1 3006.1 3006.1 3006.1 3006.1 3006.1 3006.1 3006.1 3006.1\n",
       "[291] 3006.1 3006.1 3006.1 3006.1 3006.1 3006.1 3006.1 3006.1 3006.1 3016.3\n",
       "[301] 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3\n",
       "[311] 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3\n",
       "[321] 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3716.3 3016.3 3716.3\n",
       "[331] 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3716.3 3716.3 3716.3\n",
       "[341] 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3\n",
       "[351] 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3\n",
       "[361] 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3\n",
       "[371] 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3\n",
       "[381] 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3055.8 3055.8 3055.8\n",
       "[391] 3055.8 3055.8 3055.8 3055.8 3055.8 3055.8 3055.8 3055.8 3016.3 3016.3\n",
       "[401] 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3055.8 3016.3 3055.8\n",
       "[411] 3055.8 3055.8 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3055.8 3055.8\n",
       "[421] 3055.8 3055.8 3055.8 3055.8 3055.8 3055.8 3050.6 3055.8 3055.8 3055.8\n",
       "[431] 3055.8 3055.8 3050.6 3050.6 3055.8 3055.8 3055.8 3055.8 3055.8 3055.8\n",
       "[441] 3055.8 3055.8 3055.8 3055.8 3055.8 3055.8 3055.8 3055.8 3055.8 3055.8\n",
       "[451] 3055.8 3055.8 3055.8 3055.8 3016.3 3016.3 3055.8 3055.8 3055.8 3055.8\n",
       "[461] 3055.8 3055.8 3055.8 3055.8 3055.8 3050.6 3055.8 3050.6 3055.8 3055.8\n",
       "[471] 3055.8 3055.8 3055.8 3055.8 3055.8 3055.8 3055.8 3055.8 3055.8 3055.8\n",
       "[481] 3050.6 3050.6 3050.6 3050.6 3050.6 3050.6 3050.6 3050.6 3050.6 3050.6\n",
       "[491] 3055.8 3055.8 3055.8 3055.8 3055.8 3055.8 3055.8 3055.8 3055.8 3055.8\n",
       "[501] 3055.8 3055.8 3055.8 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3\n",
       "[511] 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3\n",
       "[521] 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3\n",
       "[531] 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3\n",
       "[541] 3016.3 3016.3 3016.3 3016.3 3016.3 3016.3 3716.3 3716.3 3716.3 3716.3\n",
       "[551] 3716.3 3716.3 3016.3 3016.3 3016.3 3716.3 3716.3 3716.3 3716.3 3716.3\n",
       "[561] 3716.3 3716.3 3016.3 3716.3 3016.3 3716.3 3716.3 3716.3 3716.3 3716.3\n",
       "[571] 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3\n",
       "[581] 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3\n",
       "[591] 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3\n",
       "[601] 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3\n",
       "[611] 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3\n",
       "[621] 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3\n",
       "[631] 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3\n",
       "[641] 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3\n",
       "[651] 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3\n",
       "[661] 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3\n",
       "[671] 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3\n",
       "[681] 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3\n",
       "[691] 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3\n",
       "[701] 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3\n",
       "[711] 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3\n",
       "[721] 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 3716.3 4576.2\n",
       "[731] 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2\n",
       "[741] 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2\n",
       "[751] 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2\n",
       "[761] 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2\n",
       "[771] 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2\n",
       "[781] 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2\n",
       "[791] 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2\n",
       "[801] 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2\n",
       "[811] 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2\n",
       "[821] 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2\n",
       "[831] 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2\n",
       "[841] 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2\n",
       "[851] 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2\n",
       "[861] 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2\n",
       "[871] 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2\n",
       "[881] 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2\n",
       "[891] 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2\n",
       "[901] 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2\n",
       "[911] 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2\n",
       "[921] 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2 4576.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boot.indx <- boot(nrow(trainB.dt), 10, 3)\n",
    " indx <- boot.indx[1,]\n",
    "knn(trainB.dt[indx, ], trainB.vl[indx], testB.dt, K = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fix the parameters\n",
    "K <- 20           # Maximum K for KNN \n",
    "L <- 100          # number of datasets\n",
    "N <- 25           # size of datasets\n",
    "\n",
    "# generate bootstrap indices:\n",
    "boot.indx <- boot(nrow(trainB.dt), N, L)\n",
    "\n",
    "# a dataframe to track the number of missclassified samples in each case\n",
    "bs.miss <- data.frame('K'=1:K, 'L'=1:L, 'test'=rep(0,L*K))\n",
    "\n",
    "# THIS MAY TAKE A FEW MINUTES TO COMPLETE\n",
    "## for every k values:\n",
    "for (k in 1: K){\n",
    "    \n",
    "    ### for every dataset sizes:\n",
    "    for (l in 1:L){\n",
    "        \n",
    "        #### calculate iteration index i\n",
    "        i <- (k-1)*L+l\n",
    "        \n",
    "        #### save sample indices that were selected by bootstrap\n",
    "        indx <- boot.indx[l,]\n",
    "        \n",
    "        #### save the value of k and l\n",
    "        bs.miss[i, 'K'] <- k\n",
    "        bs.miss[i, 'L'] <- l\n",
    "        \n",
    "        #### calculate and record the train and test missclassification rates\n",
    "        bs.miss[i, 'test'] <- get.rmse(knn(trainB.dt[indx, ], trainB.vl[indx], testB.dt, K = k), testB.vl)\n",
    "    } \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the result of bootstrapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>K</th><th scope=col>L</th><th scope=col>test</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1       </td><td> 1      </td><td>178.7266</td></tr>\n",
       "\t<tr><td>1       </td><td> 2      </td><td>165.2382</td></tr>\n",
       "\t<tr><td>1       </td><td> 3      </td><td>161.2250</td></tr>\n",
       "\t<tr><td>1       </td><td> 4      </td><td>177.8648</td></tr>\n",
       "\t<tr><td>1       </td><td> 5      </td><td>238.1653</td></tr>\n",
       "\t<tr><td>1       </td><td> 6      </td><td>160.7215</td></tr>\n",
       "\t<tr><td>1       </td><td> 7      </td><td>173.4057</td></tr>\n",
       "\t<tr><td>1       </td><td> 8      </td><td>273.5447</td></tr>\n",
       "\t<tr><td>1       </td><td> 9      </td><td>203.4576</td></tr>\n",
       "\t<tr><td>1       </td><td>10      </td><td>164.4781</td></tr>\n",
       "\t<tr><td>1       </td><td>11      </td><td>143.6739</td></tr>\n",
       "\t<tr><td>1       </td><td>12      </td><td>154.4252</td></tr>\n",
       "\t<tr><td>1       </td><td>13      </td><td>150.9362</td></tr>\n",
       "\t<tr><td>1       </td><td>14      </td><td>166.9809</td></tr>\n",
       "\t<tr><td>1       </td><td>15      </td><td>222.0934</td></tr>\n",
       "\t<tr><td>1       </td><td>16      </td><td>154.0686</td></tr>\n",
       "\t<tr><td>1       </td><td>17      </td><td>190.0680</td></tr>\n",
       "\t<tr><td>1       </td><td>18      </td><td>178.0057</td></tr>\n",
       "\t<tr><td>1       </td><td>19      </td><td>239.4627</td></tr>\n",
       "\t<tr><td>1       </td><td>20      </td><td>242.4186</td></tr>\n",
       "\t<tr><td>1       </td><td>21      </td><td>151.0163</td></tr>\n",
       "\t<tr><td>1       </td><td>22      </td><td>256.4679</td></tr>\n",
       "\t<tr><td>1       </td><td>23      </td><td>262.4904</td></tr>\n",
       "\t<tr><td>1       </td><td>24      </td><td>121.1346</td></tr>\n",
       "\t<tr><td>1       </td><td>25      </td><td>169.6601</td></tr>\n",
       "\t<tr><td>1       </td><td>26      </td><td>143.9239</td></tr>\n",
       "\t<tr><td>1       </td><td>27      </td><td>136.4367</td></tr>\n",
       "\t<tr><td>1       </td><td>28      </td><td>148.9459</td></tr>\n",
       "\t<tr><td>1       </td><td>29      </td><td>151.6800</td></tr>\n",
       "\t<tr><td>1       </td><td>30      </td><td>192.7520</td></tr>\n",
       "\t<tr><td>...</td><td>...</td><td>...</td></tr>\n",
       "\t<tr><td>20      </td><td> 71     </td><td>842.1795</td></tr>\n",
       "\t<tr><td>20      </td><td> 72     </td><td>738.5153</td></tr>\n",
       "\t<tr><td>20      </td><td> 73     </td><td>848.2915</td></tr>\n",
       "\t<tr><td>20      </td><td> 74     </td><td>837.7161</td></tr>\n",
       "\t<tr><td>20      </td><td> 75     </td><td>835.3271</td></tr>\n",
       "\t<tr><td>20      </td><td> 76     </td><td>855.6810</td></tr>\n",
       "\t<tr><td>20      </td><td> 77     </td><td>729.1357</td></tr>\n",
       "\t<tr><td>20      </td><td> 78     </td><td>779.5899</td></tr>\n",
       "\t<tr><td>20      </td><td> 79     </td><td>791.9210</td></tr>\n",
       "\t<tr><td>20      </td><td> 80     </td><td>924.2885</td></tr>\n",
       "\t<tr><td>20      </td><td> 81     </td><td>757.7577</td></tr>\n",
       "\t<tr><td>20      </td><td> 82     </td><td>869.7937</td></tr>\n",
       "\t<tr><td>20      </td><td> 83     </td><td>802.3739</td></tr>\n",
       "\t<tr><td>20      </td><td> 84     </td><td>867.8006</td></tr>\n",
       "\t<tr><td>20      </td><td> 85     </td><td>900.0654</td></tr>\n",
       "\t<tr><td>20      </td><td> 86     </td><td>760.5039</td></tr>\n",
       "\t<tr><td>20      </td><td> 87     </td><td>756.7533</td></tr>\n",
       "\t<tr><td>20      </td><td> 88     </td><td>797.1670</td></tr>\n",
       "\t<tr><td>20      </td><td> 89     </td><td>914.2437</td></tr>\n",
       "\t<tr><td>20      </td><td> 90     </td><td>743.8910</td></tr>\n",
       "\t<tr><td>20      </td><td> 91     </td><td>802.8070</td></tr>\n",
       "\t<tr><td>20      </td><td> 92     </td><td>758.0172</td></tr>\n",
       "\t<tr><td>20      </td><td> 93     </td><td>781.8626</td></tr>\n",
       "\t<tr><td>20      </td><td> 94     </td><td>823.8306</td></tr>\n",
       "\t<tr><td>20      </td><td> 95     </td><td>789.4343</td></tr>\n",
       "\t<tr><td>20      </td><td> 96     </td><td>758.0362</td></tr>\n",
       "\t<tr><td>20      </td><td> 97     </td><td>745.9545</td></tr>\n",
       "\t<tr><td>20      </td><td> 98     </td><td>810.1147</td></tr>\n",
       "\t<tr><td>20      </td><td> 99     </td><td>817.1090</td></tr>\n",
       "\t<tr><td>20      </td><td>100     </td><td>853.1768</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " K & L & test\\\\\n",
       "\\hline\n",
       "\t 1        &  1       & 178.7266\\\\\n",
       "\t 1        &  2       & 165.2382\\\\\n",
       "\t 1        &  3       & 161.2250\\\\\n",
       "\t 1        &  4       & 177.8648\\\\\n",
       "\t 1        &  5       & 238.1653\\\\\n",
       "\t 1        &  6       & 160.7215\\\\\n",
       "\t 1        &  7       & 173.4057\\\\\n",
       "\t 1        &  8       & 273.5447\\\\\n",
       "\t 1        &  9       & 203.4576\\\\\n",
       "\t 1        & 10       & 164.4781\\\\\n",
       "\t 1        & 11       & 143.6739\\\\\n",
       "\t 1        & 12       & 154.4252\\\\\n",
       "\t 1        & 13       & 150.9362\\\\\n",
       "\t 1        & 14       & 166.9809\\\\\n",
       "\t 1        & 15       & 222.0934\\\\\n",
       "\t 1        & 16       & 154.0686\\\\\n",
       "\t 1        & 17       & 190.0680\\\\\n",
       "\t 1        & 18       & 178.0057\\\\\n",
       "\t 1        & 19       & 239.4627\\\\\n",
       "\t 1        & 20       & 242.4186\\\\\n",
       "\t 1        & 21       & 151.0163\\\\\n",
       "\t 1        & 22       & 256.4679\\\\\n",
       "\t 1        & 23       & 262.4904\\\\\n",
       "\t 1        & 24       & 121.1346\\\\\n",
       "\t 1        & 25       & 169.6601\\\\\n",
       "\t 1        & 26       & 143.9239\\\\\n",
       "\t 1        & 27       & 136.4367\\\\\n",
       "\t 1        & 28       & 148.9459\\\\\n",
       "\t 1        & 29       & 151.6800\\\\\n",
       "\t 1        & 30       & 192.7520\\\\\n",
       "\t ... & ... & ...\\\\\n",
       "\t 20       &  71      & 842.1795\\\\\n",
       "\t 20       &  72      & 738.5153\\\\\n",
       "\t 20       &  73      & 848.2915\\\\\n",
       "\t 20       &  74      & 837.7161\\\\\n",
       "\t 20       &  75      & 835.3271\\\\\n",
       "\t 20       &  76      & 855.6810\\\\\n",
       "\t 20       &  77      & 729.1357\\\\\n",
       "\t 20       &  78      & 779.5899\\\\\n",
       "\t 20       &  79      & 791.9210\\\\\n",
       "\t 20       &  80      & 924.2885\\\\\n",
       "\t 20       &  81      & 757.7577\\\\\n",
       "\t 20       &  82      & 869.7937\\\\\n",
       "\t 20       &  83      & 802.3739\\\\\n",
       "\t 20       &  84      & 867.8006\\\\\n",
       "\t 20       &  85      & 900.0654\\\\\n",
       "\t 20       &  86      & 760.5039\\\\\n",
       "\t 20       &  87      & 756.7533\\\\\n",
       "\t 20       &  88      & 797.1670\\\\\n",
       "\t 20       &  89      & 914.2437\\\\\n",
       "\t 20       &  90      & 743.8910\\\\\n",
       "\t 20       &  91      & 802.8070\\\\\n",
       "\t 20       &  92      & 758.0172\\\\\n",
       "\t 20       &  93      & 781.8626\\\\\n",
       "\t 20       &  94      & 823.8306\\\\\n",
       "\t 20       &  95      & 789.4343\\\\\n",
       "\t 20       &  96      & 758.0362\\\\\n",
       "\t 20       &  97      & 745.9545\\\\\n",
       "\t 20       &  98      & 810.1147\\\\\n",
       "\t 20       &  99      & 817.1090\\\\\n",
       "\t 20       & 100      & 853.1768\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "K | L | test | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1        |  1       | 178.7266 | \n",
       "| 1        |  2       | 165.2382 | \n",
       "| 1        |  3       | 161.2250 | \n",
       "| 1        |  4       | 177.8648 | \n",
       "| 1        |  5       | 238.1653 | \n",
       "| 1        |  6       | 160.7215 | \n",
       "| 1        |  7       | 173.4057 | \n",
       "| 1        |  8       | 273.5447 | \n",
       "| 1        |  9       | 203.4576 | \n",
       "| 1        | 10       | 164.4781 | \n",
       "| 1        | 11       | 143.6739 | \n",
       "| 1        | 12       | 154.4252 | \n",
       "| 1        | 13       | 150.9362 | \n",
       "| 1        | 14       | 166.9809 | \n",
       "| 1        | 15       | 222.0934 | \n",
       "| 1        | 16       | 154.0686 | \n",
       "| 1        | 17       | 190.0680 | \n",
       "| 1        | 18       | 178.0057 | \n",
       "| 1        | 19       | 239.4627 | \n",
       "| 1        | 20       | 242.4186 | \n",
       "| 1        | 21       | 151.0163 | \n",
       "| 1        | 22       | 256.4679 | \n",
       "| 1        | 23       | 262.4904 | \n",
       "| 1        | 24       | 121.1346 | \n",
       "| 1        | 25       | 169.6601 | \n",
       "| 1        | 26       | 143.9239 | \n",
       "| 1        | 27       | 136.4367 | \n",
       "| 1        | 28       | 148.9459 | \n",
       "| 1        | 29       | 151.6800 | \n",
       "| 1        | 30       | 192.7520 | \n",
       "| ... | ... | ... | \n",
       "| 20       |  71      | 842.1795 | \n",
       "| 20       |  72      | 738.5153 | \n",
       "| 20       |  73      | 848.2915 | \n",
       "| 20       |  74      | 837.7161 | \n",
       "| 20       |  75      | 835.3271 | \n",
       "| 20       |  76      | 855.6810 | \n",
       "| 20       |  77      | 729.1357 | \n",
       "| 20       |  78      | 779.5899 | \n",
       "| 20       |  79      | 791.9210 | \n",
       "| 20       |  80      | 924.2885 | \n",
       "| 20       |  81      | 757.7577 | \n",
       "| 20       |  82      | 869.7937 | \n",
       "| 20       |  83      | 802.3739 | \n",
       "| 20       |  84      | 867.8006 | \n",
       "| 20       |  85      | 900.0654 | \n",
       "| 20       |  86      | 760.5039 | \n",
       "| 20       |  87      | 756.7533 | \n",
       "| 20       |  88      | 797.1670 | \n",
       "| 20       |  89      | 914.2437 | \n",
       "| 20       |  90      | 743.8910 | \n",
       "| 20       |  91      | 802.8070 | \n",
       "| 20       |  92      | 758.0172 | \n",
       "| 20       |  93      | 781.8626 | \n",
       "| 20       |  94      | 823.8306 | \n",
       "| 20       |  95      | 789.4343 | \n",
       "| 20       |  96      | 758.0362 | \n",
       "| 20       |  97      | 745.9545 | \n",
       "| 20       |  98      | 810.1147 | \n",
       "| 20       |  99      | 817.1090 | \n",
       "| 20       | 100      | 853.1768 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     K   L   test    \n",
       "1    1    1  178.7266\n",
       "2    1    2  165.2382\n",
       "3    1    3  161.2250\n",
       "4    1    4  177.8648\n",
       "5    1    5  238.1653\n",
       "6    1    6  160.7215\n",
       "7    1    7  173.4057\n",
       "8    1    8  273.5447\n",
       "9    1    9  203.4576\n",
       "10   1   10  164.4781\n",
       "11   1   11  143.6739\n",
       "12   1   12  154.4252\n",
       "13   1   13  150.9362\n",
       "14   1   14  166.9809\n",
       "15   1   15  222.0934\n",
       "16   1   16  154.0686\n",
       "17   1   17  190.0680\n",
       "18   1   18  178.0057\n",
       "19   1   19  239.4627\n",
       "20   1   20  242.4186\n",
       "21   1   21  151.0163\n",
       "22   1   22  256.4679\n",
       "23   1   23  262.4904\n",
       "24   1   24  121.1346\n",
       "25   1   25  169.6601\n",
       "26   1   26  143.9239\n",
       "27   1   27  136.4367\n",
       "28   1   28  148.9459\n",
       "29   1   29  151.6800\n",
       "30   1   30  192.7520\n",
       "...  ... ... ...     \n",
       "1971 20   71 842.1795\n",
       "1972 20   72 738.5153\n",
       "1973 20   73 848.2915\n",
       "1974 20   74 837.7161\n",
       "1975 20   75 835.3271\n",
       "1976 20   76 855.6810\n",
       "1977 20   77 729.1357\n",
       "1978 20   78 779.5899\n",
       "1979 20   79 791.9210\n",
       "1980 20   80 924.2885\n",
       "1981 20   81 757.7577\n",
       "1982 20   82 869.7937\n",
       "1983 20   83 802.3739\n",
       "1984 20   84 867.8006\n",
       "1985 20   85 900.0654\n",
       "1986 20   86 760.5039\n",
       "1987 20   87 756.7533\n",
       "1988 20   88 797.1670\n",
       "1989 20   89 914.2437\n",
       "1990 20   90 743.8910\n",
       "1991 20   91 802.8070\n",
       "1992 20   92 758.0172\n",
       "1993 20   93 781.8626\n",
       "1994 20   94 823.8306\n",
       "1995 20   95 789.4343\n",
       "1996 20   96 758.0362\n",
       "1997 20   97 745.9545\n",
       "1998 20   98 810.1147\n",
       "1999 20   99 817.1090\n",
       "2000 20  100 853.1768"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check the result of bootstrapping\n",
    "bs.miss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use it to graph the errors and check for any patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAOVBMVEUAAAAzMzNNTU1oaGh8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\nAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot misclassification percentage for train and test data sets\n",
    "bs.miss.m <- melt(bs.miss, id=c('K', 'L')) # reshape for visualization\n",
    "names(bs.miss.m) <- c('K', 'L', 'type', 'error')\n",
    "ggplot(data=bs.miss.m[bs.miss.m$type=='test',], aes(factor(K), error,fill=type)) + geom_boxplot(outlier.shape = NA)  + \n",
    "    scale_color_discrete(guide = guide_legend(title = NULL)) + \n",
    "    ggtitle('Errors (RMSE) vs. K (Box Plot)') + theme_minimal()\n",
    "# ignore the warnings (because of ignoring outliers)\n",
    "options(warn=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3-3**\n",
    "\n",
    "Q3-3) Based on your plot in the previous sub-question, Q3-2, how does the test error and its uncertainty behave as K increases? \n",
    "\n",
    "**Answer**\n",
    "\n",
    "The errors and uncertainty tend to **increase** as K increases. As shown from the graph, the maximum error increases from around ~250 when K = 1 to ~900 when K = 20.\n",
    "\n",
    "The variance among errors can also be seen in the boxplot. There is very little variance among errors when K is too small (1 to 2) and K is too large (19 to 20). However, the variance is at all time high when K is at the middle K = 10.\n",
    "\n",
    "Q3-4) Load Task1B_train.csv and Task1B_test.csv sets. Apply your bootstrapping for KNN regression with K=10 (the neighbourhood size), size = 25 (the size of each subset), and change times = 10, 20, 30,.., 200 (the number of subsets). Now create a boxplot where the x-axis is â€˜timesâ€™, and the y-axis is the average error (and the uncertainty around it) corresponding to each value of â€˜timesâ€™.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "2100"
      ],
      "text/latex": [
       "2100"
      ],
      "text/markdown": [
       "2100"
      ],
      "text/plain": [
       "[1] 2100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "L <- c(10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200) # number of datasets\n",
    "sum(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fix the parameters\n",
    "K <- 10\n",
    "L <- c(10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200) # number of datasets\n",
    "N <- 25          # size of datasets\n",
    "\n",
    "# a dataframe to track the number of missclassified samples in each case\n",
    "times.miss <- data.frame('L'= rep(0, 2100),'index'=rep(0, 2100),'test'=rep(0,2100))\n",
    "\n",
    "i <- 0\n",
    "                   \n",
    "### for every dataset sizes:\n",
    "for (l in L){\n",
    "    # generate bootstrap indices:\n",
    "    boot.indx <- boot(nrow(trainB.dt),N,l)\n",
    "    rmse <- c()\n",
    "    \n",
    "    # for every bootstrap\n",
    "    for (j in 1:l){\n",
    "        i <- i + 1\n",
    "        #### save sample indices that were selected by bootstrap\n",
    "        indx <- boot.indx[j,]\n",
    "        \n",
    "        #### save the value of l and j (bootstrap element index)\n",
    "        times.miss[i,'L'] <- l \n",
    "        times.miss[i,'index'] <- j\n",
    "        \n",
    "        # get the RMSE\n",
    "        rmse <- get.rmse(knn(trainB.dt[indx,],trainB.vl[indx],testB.dt,K=k),testB.vl)\n",
    "        times.miss[i,'test'] <- rmse\n",
    "    }\n",
    "} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>L</th><th scope=col>index</th><th scope=col>test</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>10      </td><td> 1      </td><td>851.0804</td></tr>\n",
       "\t<tr><td>10      </td><td> 2      </td><td>774.8379</td></tr>\n",
       "\t<tr><td>10      </td><td> 3      </td><td>772.6149</td></tr>\n",
       "\t<tr><td>10      </td><td> 4      </td><td>883.9133</td></tr>\n",
       "\t<tr><td>10      </td><td> 5      </td><td>784.3907</td></tr>\n",
       "\t<tr><td>10      </td><td> 6      </td><td>818.8062</td></tr>\n",
       "\t<tr><td>10      </td><td> 7      </td><td>729.2418</td></tr>\n",
       "\t<tr><td>10      </td><td> 8      </td><td>791.5768</td></tr>\n",
       "\t<tr><td>10      </td><td> 9      </td><td>790.6785</td></tr>\n",
       "\t<tr><td>10      </td><td>10      </td><td>745.9502</td></tr>\n",
       "\t<tr><td>20      </td><td> 1      </td><td>867.0710</td></tr>\n",
       "\t<tr><td>20      </td><td> 2      </td><td>771.9619</td></tr>\n",
       "\t<tr><td>20      </td><td> 3      </td><td>810.7255</td></tr>\n",
       "\t<tr><td>20      </td><td> 4      </td><td>735.8447</td></tr>\n",
       "\t<tr><td>20      </td><td> 5      </td><td>825.0894</td></tr>\n",
       "\t<tr><td>20      </td><td> 6      </td><td>868.2319</td></tr>\n",
       "\t<tr><td>20      </td><td> 7      </td><td>735.7226</td></tr>\n",
       "\t<tr><td>20      </td><td> 8      </td><td>770.5913</td></tr>\n",
       "\t<tr><td>20      </td><td> 9      </td><td>811.1511</td></tr>\n",
       "\t<tr><td>20      </td><td>10      </td><td>735.0389</td></tr>\n",
       "\t<tr><td>20      </td><td>11      </td><td>745.6186</td></tr>\n",
       "\t<tr><td>20      </td><td>12      </td><td>820.5782</td></tr>\n",
       "\t<tr><td>20      </td><td>13      </td><td>761.1836</td></tr>\n",
       "\t<tr><td>20      </td><td>14      </td><td>774.9089</td></tr>\n",
       "\t<tr><td>20      </td><td>15      </td><td>760.9695</td></tr>\n",
       "\t<tr><td>20      </td><td>16      </td><td>764.6245</td></tr>\n",
       "\t<tr><td>20      </td><td>17      </td><td>828.1449</td></tr>\n",
       "\t<tr><td>20      </td><td>18      </td><td>766.6081</td></tr>\n",
       "\t<tr><td>20      </td><td>19      </td><td>730.9132</td></tr>\n",
       "\t<tr><td>20      </td><td>20      </td><td>764.7492</td></tr>\n",
       "\t<tr><td>...</td><td>...</td><td>...</td></tr>\n",
       "\t<tr><td>40      </td><td>11      </td><td>750.2435</td></tr>\n",
       "\t<tr><td>40      </td><td>12      </td><td>818.2052</td></tr>\n",
       "\t<tr><td>40      </td><td>13      </td><td>855.6031</td></tr>\n",
       "\t<tr><td>40      </td><td>14      </td><td>844.3440</td></tr>\n",
       "\t<tr><td>40      </td><td>15      </td><td>809.6473</td></tr>\n",
       "\t<tr><td>40      </td><td>16      </td><td>781.6520</td></tr>\n",
       "\t<tr><td>40      </td><td>17      </td><td>791.4902</td></tr>\n",
       "\t<tr><td>40      </td><td>18      </td><td>839.2024</td></tr>\n",
       "\t<tr><td>40      </td><td>19      </td><td>769.1166</td></tr>\n",
       "\t<tr><td>40      </td><td>20      </td><td>793.9519</td></tr>\n",
       "\t<tr><td>40      </td><td>21      </td><td>869.7865</td></tr>\n",
       "\t<tr><td>40      </td><td>22      </td><td>813.2157</td></tr>\n",
       "\t<tr><td>40      </td><td>23      </td><td>778.6557</td></tr>\n",
       "\t<tr><td>40      </td><td>24      </td><td>760.9789</td></tr>\n",
       "\t<tr><td>40      </td><td>25      </td><td>882.4230</td></tr>\n",
       "\t<tr><td>40      </td><td>26      </td><td>804.4081</td></tr>\n",
       "\t<tr><td>40      </td><td>27      </td><td>799.7391</td></tr>\n",
       "\t<tr><td>40      </td><td>28      </td><td>737.2656</td></tr>\n",
       "\t<tr><td>40      </td><td>29      </td><td>810.3621</td></tr>\n",
       "\t<tr><td>40      </td><td>30      </td><td>751.9481</td></tr>\n",
       "\t<tr><td>40      </td><td>31      </td><td>765.0106</td></tr>\n",
       "\t<tr><td>40      </td><td>32      </td><td>824.5173</td></tr>\n",
       "\t<tr><td>40      </td><td>33      </td><td>828.0464</td></tr>\n",
       "\t<tr><td>40      </td><td>34      </td><td>854.4762</td></tr>\n",
       "\t<tr><td>40      </td><td>35      </td><td>802.1320</td></tr>\n",
       "\t<tr><td>40      </td><td>36      </td><td>885.6677</td></tr>\n",
       "\t<tr><td>40      </td><td>37      </td><td>806.9053</td></tr>\n",
       "\t<tr><td>40      </td><td>38      </td><td>759.9037</td></tr>\n",
       "\t<tr><td>40      </td><td>39      </td><td>775.9323</td></tr>\n",
       "\t<tr><td>40      </td><td>40      </td><td>775.8843</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " L & index & test\\\\\n",
       "\\hline\n",
       "\t 10       &  1       & 851.0804\\\\\n",
       "\t 10       &  2       & 774.8379\\\\\n",
       "\t 10       &  3       & 772.6149\\\\\n",
       "\t 10       &  4       & 883.9133\\\\\n",
       "\t 10       &  5       & 784.3907\\\\\n",
       "\t 10       &  6       & 818.8062\\\\\n",
       "\t 10       &  7       & 729.2418\\\\\n",
       "\t 10       &  8       & 791.5768\\\\\n",
       "\t 10       &  9       & 790.6785\\\\\n",
       "\t 10       & 10       & 745.9502\\\\\n",
       "\t 20       &  1       & 867.0710\\\\\n",
       "\t 20       &  2       & 771.9619\\\\\n",
       "\t 20       &  3       & 810.7255\\\\\n",
       "\t 20       &  4       & 735.8447\\\\\n",
       "\t 20       &  5       & 825.0894\\\\\n",
       "\t 20       &  6       & 868.2319\\\\\n",
       "\t 20       &  7       & 735.7226\\\\\n",
       "\t 20       &  8       & 770.5913\\\\\n",
       "\t 20       &  9       & 811.1511\\\\\n",
       "\t 20       & 10       & 735.0389\\\\\n",
       "\t 20       & 11       & 745.6186\\\\\n",
       "\t 20       & 12       & 820.5782\\\\\n",
       "\t 20       & 13       & 761.1836\\\\\n",
       "\t 20       & 14       & 774.9089\\\\\n",
       "\t 20       & 15       & 760.9695\\\\\n",
       "\t 20       & 16       & 764.6245\\\\\n",
       "\t 20       & 17       & 828.1449\\\\\n",
       "\t 20       & 18       & 766.6081\\\\\n",
       "\t 20       & 19       & 730.9132\\\\\n",
       "\t 20       & 20       & 764.7492\\\\\n",
       "\t ... & ... & ...\\\\\n",
       "\t 40       & 11       & 750.2435\\\\\n",
       "\t 40       & 12       & 818.2052\\\\\n",
       "\t 40       & 13       & 855.6031\\\\\n",
       "\t 40       & 14       & 844.3440\\\\\n",
       "\t 40       & 15       & 809.6473\\\\\n",
       "\t 40       & 16       & 781.6520\\\\\n",
       "\t 40       & 17       & 791.4902\\\\\n",
       "\t 40       & 18       & 839.2024\\\\\n",
       "\t 40       & 19       & 769.1166\\\\\n",
       "\t 40       & 20       & 793.9519\\\\\n",
       "\t 40       & 21       & 869.7865\\\\\n",
       "\t 40       & 22       & 813.2157\\\\\n",
       "\t 40       & 23       & 778.6557\\\\\n",
       "\t 40       & 24       & 760.9789\\\\\n",
       "\t 40       & 25       & 882.4230\\\\\n",
       "\t 40       & 26       & 804.4081\\\\\n",
       "\t 40       & 27       & 799.7391\\\\\n",
       "\t 40       & 28       & 737.2656\\\\\n",
       "\t 40       & 29       & 810.3621\\\\\n",
       "\t 40       & 30       & 751.9481\\\\\n",
       "\t 40       & 31       & 765.0106\\\\\n",
       "\t 40       & 32       & 824.5173\\\\\n",
       "\t 40       & 33       & 828.0464\\\\\n",
       "\t 40       & 34       & 854.4762\\\\\n",
       "\t 40       & 35       & 802.1320\\\\\n",
       "\t 40       & 36       & 885.6677\\\\\n",
       "\t 40       & 37       & 806.9053\\\\\n",
       "\t 40       & 38       & 759.9037\\\\\n",
       "\t 40       & 39       & 775.9323\\\\\n",
       "\t 40       & 40       & 775.8843\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "L | index | test | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 10       |  1       | 851.0804 | \n",
       "| 10       |  2       | 774.8379 | \n",
       "| 10       |  3       | 772.6149 | \n",
       "| 10       |  4       | 883.9133 | \n",
       "| 10       |  5       | 784.3907 | \n",
       "| 10       |  6       | 818.8062 | \n",
       "| 10       |  7       | 729.2418 | \n",
       "| 10       |  8       | 791.5768 | \n",
       "| 10       |  9       | 790.6785 | \n",
       "| 10       | 10       | 745.9502 | \n",
       "| 20       |  1       | 867.0710 | \n",
       "| 20       |  2       | 771.9619 | \n",
       "| 20       |  3       | 810.7255 | \n",
       "| 20       |  4       | 735.8447 | \n",
       "| 20       |  5       | 825.0894 | \n",
       "| 20       |  6       | 868.2319 | \n",
       "| 20       |  7       | 735.7226 | \n",
       "| 20       |  8       | 770.5913 | \n",
       "| 20       |  9       | 811.1511 | \n",
       "| 20       | 10       | 735.0389 | \n",
       "| 20       | 11       | 745.6186 | \n",
       "| 20       | 12       | 820.5782 | \n",
       "| 20       | 13       | 761.1836 | \n",
       "| 20       | 14       | 774.9089 | \n",
       "| 20       | 15       | 760.9695 | \n",
       "| 20       | 16       | 764.6245 | \n",
       "| 20       | 17       | 828.1449 | \n",
       "| 20       | 18       | 766.6081 | \n",
       "| 20       | 19       | 730.9132 | \n",
       "| 20       | 20       | 764.7492 | \n",
       "| ... | ... | ... | \n",
       "| 40       | 11       | 750.2435 | \n",
       "| 40       | 12       | 818.2052 | \n",
       "| 40       | 13       | 855.6031 | \n",
       "| 40       | 14       | 844.3440 | \n",
       "| 40       | 15       | 809.6473 | \n",
       "| 40       | 16       | 781.6520 | \n",
       "| 40       | 17       | 791.4902 | \n",
       "| 40       | 18       | 839.2024 | \n",
       "| 40       | 19       | 769.1166 | \n",
       "| 40       | 20       | 793.9519 | \n",
       "| 40       | 21       | 869.7865 | \n",
       "| 40       | 22       | 813.2157 | \n",
       "| 40       | 23       | 778.6557 | \n",
       "| 40       | 24       | 760.9789 | \n",
       "| 40       | 25       | 882.4230 | \n",
       "| 40       | 26       | 804.4081 | \n",
       "| 40       | 27       | 799.7391 | \n",
       "| 40       | 28       | 737.2656 | \n",
       "| 40       | 29       | 810.3621 | \n",
       "| 40       | 30       | 751.9481 | \n",
       "| 40       | 31       | 765.0106 | \n",
       "| 40       | 32       | 824.5173 | \n",
       "| 40       | 33       | 828.0464 | \n",
       "| 40       | 34       | 854.4762 | \n",
       "| 40       | 35       | 802.1320 | \n",
       "| 40       | 36       | 885.6677 | \n",
       "| 40       | 37       | 806.9053 | \n",
       "| 40       | 38       | 759.9037 | \n",
       "| 40       | 39       | 775.9323 | \n",
       "| 40       | 40       | 775.8843 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "    L   index test    \n",
       "1   10   1    851.0804\n",
       "2   10   2    774.8379\n",
       "3   10   3    772.6149\n",
       "4   10   4    883.9133\n",
       "5   10   5    784.3907\n",
       "6   10   6    818.8062\n",
       "7   10   7    729.2418\n",
       "8   10   8    791.5768\n",
       "9   10   9    790.6785\n",
       "10  10  10    745.9502\n",
       "11  20   1    867.0710\n",
       "12  20   2    771.9619\n",
       "13  20   3    810.7255\n",
       "14  20   4    735.8447\n",
       "15  20   5    825.0894\n",
       "16  20   6    868.2319\n",
       "17  20   7    735.7226\n",
       "18  20   8    770.5913\n",
       "19  20   9    811.1511\n",
       "20  20  10    735.0389\n",
       "21  20  11    745.6186\n",
       "22  20  12    820.5782\n",
       "23  20  13    761.1836\n",
       "24  20  14    774.9089\n",
       "25  20  15    760.9695\n",
       "26  20  16    764.6245\n",
       "27  20  17    828.1449\n",
       "28  20  18    766.6081\n",
       "29  20  19    730.9132\n",
       "30  20  20    764.7492\n",
       "... ... ...   ...     \n",
       "71  40  11    750.2435\n",
       "72  40  12    818.2052\n",
       "73  40  13    855.6031\n",
       "74  40  14    844.3440\n",
       "75  40  15    809.6473\n",
       "76  40  16    781.6520\n",
       "77  40  17    791.4902\n",
       "78  40  18    839.2024\n",
       "79  40  19    769.1166\n",
       "80  40  20    793.9519\n",
       "81  40  21    869.7865\n",
       "82  40  22    813.2157\n",
       "83  40  23    778.6557\n",
       "84  40  24    760.9789\n",
       "85  40  25    882.4230\n",
       "86  40  26    804.4081\n",
       "87  40  27    799.7391\n",
       "88  40  28    737.2656\n",
       "89  40  29    810.3621\n",
       "90  40  30    751.9481\n",
       "91  40  31    765.0106\n",
       "92  40  32    824.5173\n",
       "93  40  33    828.0464\n",
       "94  40  34    854.4762\n",
       "95  40  35    802.1320\n",
       "96  40  36    885.6677\n",
       "97  40  37    806.9053\n",
       "98  40  38    759.9037\n",
       "99  40  39    775.9323\n",
       "100 40  40    775.8843"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "2100"
      ],
      "text/latex": [
       "2100"
      ],
      "text/markdown": [
       "2100"
      ],
      "text/plain": [
       "[1] 2100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>L</th><th scope=col>index</th><th scope=col>test</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1500</th><td>170     </td><td>140     </td><td>873.3036</td></tr>\n",
       "\t<tr><th scope=row>1501</th><td>170     </td><td>141     </td><td>900.3430</td></tr>\n",
       "\t<tr><th scope=row>1502</th><td>170     </td><td>142     </td><td>769.4254</td></tr>\n",
       "\t<tr><th scope=row>1503</th><td>170     </td><td>143     </td><td>788.6857</td></tr>\n",
       "\t<tr><th scope=row>1504</th><td>170     </td><td>144     </td><td>806.9222</td></tr>\n",
       "\t<tr><th scope=row>1505</th><td>170     </td><td>145     </td><td>753.7217</td></tr>\n",
       "\t<tr><th scope=row>1506</th><td>170     </td><td>146     </td><td>817.1295</td></tr>\n",
       "\t<tr><th scope=row>1507</th><td>170     </td><td>147     </td><td>735.1616</td></tr>\n",
       "\t<tr><th scope=row>1508</th><td>170     </td><td>148     </td><td>865.3539</td></tr>\n",
       "\t<tr><th scope=row>1509</th><td>170     </td><td>149     </td><td>819.5086</td></tr>\n",
       "\t<tr><th scope=row>1510</th><td>170     </td><td>150     </td><td>798.2229</td></tr>\n",
       "\t<tr><th scope=row>1511</th><td>170     </td><td>151     </td><td>776.8275</td></tr>\n",
       "\t<tr><th scope=row>1512</th><td>170     </td><td>152     </td><td>818.1743</td></tr>\n",
       "\t<tr><th scope=row>1513</th><td>170     </td><td>153     </td><td>784.9936</td></tr>\n",
       "\t<tr><th scope=row>1514</th><td>170     </td><td>154     </td><td>862.6428</td></tr>\n",
       "\t<tr><th scope=row>1515</th><td>170     </td><td>155     </td><td>828.4469</td></tr>\n",
       "\t<tr><th scope=row>1516</th><td>170     </td><td>156     </td><td>830.3460</td></tr>\n",
       "\t<tr><th scope=row>1517</th><td>170     </td><td>157     </td><td>728.4254</td></tr>\n",
       "\t<tr><th scope=row>1518</th><td>170     </td><td>158     </td><td>863.3263</td></tr>\n",
       "\t<tr><th scope=row>1519</th><td>170     </td><td>159     </td><td>853.2715</td></tr>\n",
       "\t<tr><th scope=row>1520</th><td>170     </td><td>160     </td><td>819.8846</td></tr>\n",
       "\t<tr><th scope=row>1521</th><td>170     </td><td>161     </td><td>915.3225</td></tr>\n",
       "\t<tr><th scope=row>1522</th><td>170     </td><td>162     </td><td>779.2412</td></tr>\n",
       "\t<tr><th scope=row>1523</th><td>170     </td><td>163     </td><td>747.8102</td></tr>\n",
       "\t<tr><th scope=row>1524</th><td>170     </td><td>164     </td><td>900.5734</td></tr>\n",
       "\t<tr><th scope=row>1525</th><td>170     </td><td>165     </td><td>817.9562</td></tr>\n",
       "\t<tr><th scope=row>1526</th><td>170     </td><td>166     </td><td>851.3701</td></tr>\n",
       "\t<tr><th scope=row>1527</th><td>170     </td><td>167     </td><td>771.8213</td></tr>\n",
       "\t<tr><th scope=row>1528</th><td>170     </td><td>168     </td><td>768.3620</td></tr>\n",
       "\t<tr><th scope=row>1529</th><td>170     </td><td>169     </td><td>783.4469</td></tr>\n",
       "\t<tr><th scope=row>...</th><td>...</td><td>...</td><td>...</td></tr>\n",
       "\t<tr><th scope=row>1571</th><td>180     </td><td>41      </td><td>801.7464</td></tr>\n",
       "\t<tr><th scope=row>1572</th><td>180     </td><td>42      </td><td>827.3688</td></tr>\n",
       "\t<tr><th scope=row>1573</th><td>180     </td><td>43      </td><td>905.2295</td></tr>\n",
       "\t<tr><th scope=row>1574</th><td>180     </td><td>44      </td><td>725.0322</td></tr>\n",
       "\t<tr><th scope=row>1575</th><td>180     </td><td>45      </td><td>777.7240</td></tr>\n",
       "\t<tr><th scope=row>1576</th><td>180     </td><td>46      </td><td>826.0509</td></tr>\n",
       "\t<tr><th scope=row>1577</th><td>180     </td><td>47      </td><td>806.9876</td></tr>\n",
       "\t<tr><th scope=row>1578</th><td>180     </td><td>48      </td><td>762.1261</td></tr>\n",
       "\t<tr><th scope=row>1579</th><td>180     </td><td>49      </td><td>870.1524</td></tr>\n",
       "\t<tr><th scope=row>1580</th><td>180     </td><td>50      </td><td>799.5588</td></tr>\n",
       "\t<tr><th scope=row>1581</th><td>180     </td><td>51      </td><td>795.7737</td></tr>\n",
       "\t<tr><th scope=row>1582</th><td>180     </td><td>52      </td><td>843.1882</td></tr>\n",
       "\t<tr><th scope=row>1583</th><td>180     </td><td>53      </td><td>859.9428</td></tr>\n",
       "\t<tr><th scope=row>1584</th><td>180     </td><td>54      </td><td>832.8972</td></tr>\n",
       "\t<tr><th scope=row>1585</th><td>180     </td><td>55      </td><td>783.4779</td></tr>\n",
       "\t<tr><th scope=row>1586</th><td>180     </td><td>56      </td><td>805.0465</td></tr>\n",
       "\t<tr><th scope=row>1587</th><td>180     </td><td>57      </td><td>821.0813</td></tr>\n",
       "\t<tr><th scope=row>1588</th><td>180     </td><td>58      </td><td>752.0632</td></tr>\n",
       "\t<tr><th scope=row>1589</th><td>180     </td><td>59      </td><td>756.6053</td></tr>\n",
       "\t<tr><th scope=row>1590</th><td>180     </td><td>60      </td><td>826.2303</td></tr>\n",
       "\t<tr><th scope=row>1591</th><td>180     </td><td>61      </td><td>820.0856</td></tr>\n",
       "\t<tr><th scope=row>1592</th><td>180     </td><td>62      </td><td>792.1916</td></tr>\n",
       "\t<tr><th scope=row>1593</th><td>180     </td><td>63      </td><td>789.5333</td></tr>\n",
       "\t<tr><th scope=row>1594</th><td>180     </td><td>64      </td><td>802.3494</td></tr>\n",
       "\t<tr><th scope=row>1595</th><td>180     </td><td>65      </td><td>760.4543</td></tr>\n",
       "\t<tr><th scope=row>1596</th><td>180     </td><td>66      </td><td>780.5930</td></tr>\n",
       "\t<tr><th scope=row>1597</th><td>180     </td><td>67      </td><td>792.8144</td></tr>\n",
       "\t<tr><th scope=row>1598</th><td>180     </td><td>68      </td><td>760.7032</td></tr>\n",
       "\t<tr><th scope=row>1599</th><td>180     </td><td>69      </td><td>767.3441</td></tr>\n",
       "\t<tr><th scope=row>1600</th><td>180     </td><td>70      </td><td>784.9863</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       "  & L & index & test\\\\\n",
       "\\hline\n",
       "\t1500 & 170      & 140      & 873.3036\\\\\n",
       "\t1501 & 170      & 141      & 900.3430\\\\\n",
       "\t1502 & 170      & 142      & 769.4254\\\\\n",
       "\t1503 & 170      & 143      & 788.6857\\\\\n",
       "\t1504 & 170      & 144      & 806.9222\\\\\n",
       "\t1505 & 170      & 145      & 753.7217\\\\\n",
       "\t1506 & 170      & 146      & 817.1295\\\\\n",
       "\t1507 & 170      & 147      & 735.1616\\\\\n",
       "\t1508 & 170      & 148      & 865.3539\\\\\n",
       "\t1509 & 170      & 149      & 819.5086\\\\\n",
       "\t1510 & 170      & 150      & 798.2229\\\\\n",
       "\t1511 & 170      & 151      & 776.8275\\\\\n",
       "\t1512 & 170      & 152      & 818.1743\\\\\n",
       "\t1513 & 170      & 153      & 784.9936\\\\\n",
       "\t1514 & 170      & 154      & 862.6428\\\\\n",
       "\t1515 & 170      & 155      & 828.4469\\\\\n",
       "\t1516 & 170      & 156      & 830.3460\\\\\n",
       "\t1517 & 170      & 157      & 728.4254\\\\\n",
       "\t1518 & 170      & 158      & 863.3263\\\\\n",
       "\t1519 & 170      & 159      & 853.2715\\\\\n",
       "\t1520 & 170      & 160      & 819.8846\\\\\n",
       "\t1521 & 170      & 161      & 915.3225\\\\\n",
       "\t1522 & 170      & 162      & 779.2412\\\\\n",
       "\t1523 & 170      & 163      & 747.8102\\\\\n",
       "\t1524 & 170      & 164      & 900.5734\\\\\n",
       "\t1525 & 170      & 165      & 817.9562\\\\\n",
       "\t1526 & 170      & 166      & 851.3701\\\\\n",
       "\t1527 & 170      & 167      & 771.8213\\\\\n",
       "\t1528 & 170      & 168      & 768.3620\\\\\n",
       "\t1529 & 170      & 169      & 783.4469\\\\\n",
       "\t... & ... & ... & ...\\\\\n",
       "\t1571 & 180      & 41       & 801.7464\\\\\n",
       "\t1572 & 180      & 42       & 827.3688\\\\\n",
       "\t1573 & 180      & 43       & 905.2295\\\\\n",
       "\t1574 & 180      & 44       & 725.0322\\\\\n",
       "\t1575 & 180      & 45       & 777.7240\\\\\n",
       "\t1576 & 180      & 46       & 826.0509\\\\\n",
       "\t1577 & 180      & 47       & 806.9876\\\\\n",
       "\t1578 & 180      & 48       & 762.1261\\\\\n",
       "\t1579 & 180      & 49       & 870.1524\\\\\n",
       "\t1580 & 180      & 50       & 799.5588\\\\\n",
       "\t1581 & 180      & 51       & 795.7737\\\\\n",
       "\t1582 & 180      & 52       & 843.1882\\\\\n",
       "\t1583 & 180      & 53       & 859.9428\\\\\n",
       "\t1584 & 180      & 54       & 832.8972\\\\\n",
       "\t1585 & 180      & 55       & 783.4779\\\\\n",
       "\t1586 & 180      & 56       & 805.0465\\\\\n",
       "\t1587 & 180      & 57       & 821.0813\\\\\n",
       "\t1588 & 180      & 58       & 752.0632\\\\\n",
       "\t1589 & 180      & 59       & 756.6053\\\\\n",
       "\t1590 & 180      & 60       & 826.2303\\\\\n",
       "\t1591 & 180      & 61       & 820.0856\\\\\n",
       "\t1592 & 180      & 62       & 792.1916\\\\\n",
       "\t1593 & 180      & 63       & 789.5333\\\\\n",
       "\t1594 & 180      & 64       & 802.3494\\\\\n",
       "\t1595 & 180      & 65       & 760.4543\\\\\n",
       "\t1596 & 180      & 66       & 780.5930\\\\\n",
       "\t1597 & 180      & 67       & 792.8144\\\\\n",
       "\t1598 & 180      & 68       & 760.7032\\\\\n",
       "\t1599 & 180      & 69       & 767.3441\\\\\n",
       "\t1600 & 180      & 70       & 784.9863\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | L | index | test | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1500 | 170      | 140      | 873.3036 | \n",
       "| 1501 | 170      | 141      | 900.3430 | \n",
       "| 1502 | 170      | 142      | 769.4254 | \n",
       "| 1503 | 170      | 143      | 788.6857 | \n",
       "| 1504 | 170      | 144      | 806.9222 | \n",
       "| 1505 | 170      | 145      | 753.7217 | \n",
       "| 1506 | 170      | 146      | 817.1295 | \n",
       "| 1507 | 170      | 147      | 735.1616 | \n",
       "| 1508 | 170      | 148      | 865.3539 | \n",
       "| 1509 | 170      | 149      | 819.5086 | \n",
       "| 1510 | 170      | 150      | 798.2229 | \n",
       "| 1511 | 170      | 151      | 776.8275 | \n",
       "| 1512 | 170      | 152      | 818.1743 | \n",
       "| 1513 | 170      | 153      | 784.9936 | \n",
       "| 1514 | 170      | 154      | 862.6428 | \n",
       "| 1515 | 170      | 155      | 828.4469 | \n",
       "| 1516 | 170      | 156      | 830.3460 | \n",
       "| 1517 | 170      | 157      | 728.4254 | \n",
       "| 1518 | 170      | 158      | 863.3263 | \n",
       "| 1519 | 170      | 159      | 853.2715 | \n",
       "| 1520 | 170      | 160      | 819.8846 | \n",
       "| 1521 | 170      | 161      | 915.3225 | \n",
       "| 1522 | 170      | 162      | 779.2412 | \n",
       "| 1523 | 170      | 163      | 747.8102 | \n",
       "| 1524 | 170      | 164      | 900.5734 | \n",
       "| 1525 | 170      | 165      | 817.9562 | \n",
       "| 1526 | 170      | 166      | 851.3701 | \n",
       "| 1527 | 170      | 167      | 771.8213 | \n",
       "| 1528 | 170      | 168      | 768.3620 | \n",
       "| 1529 | 170      | 169      | 783.4469 | \n",
       "| ... | ... | ... | ... | \n",
       "| 1571 | 180      | 41       | 801.7464 | \n",
       "| 1572 | 180      | 42       | 827.3688 | \n",
       "| 1573 | 180      | 43       | 905.2295 | \n",
       "| 1574 | 180      | 44       | 725.0322 | \n",
       "| 1575 | 180      | 45       | 777.7240 | \n",
       "| 1576 | 180      | 46       | 826.0509 | \n",
       "| 1577 | 180      | 47       | 806.9876 | \n",
       "| 1578 | 180      | 48       | 762.1261 | \n",
       "| 1579 | 180      | 49       | 870.1524 | \n",
       "| 1580 | 180      | 50       | 799.5588 | \n",
       "| 1581 | 180      | 51       | 795.7737 | \n",
       "| 1582 | 180      | 52       | 843.1882 | \n",
       "| 1583 | 180      | 53       | 859.9428 | \n",
       "| 1584 | 180      | 54       | 832.8972 | \n",
       "| 1585 | 180      | 55       | 783.4779 | \n",
       "| 1586 | 180      | 56       | 805.0465 | \n",
       "| 1587 | 180      | 57       | 821.0813 | \n",
       "| 1588 | 180      | 58       | 752.0632 | \n",
       "| 1589 | 180      | 59       | 756.6053 | \n",
       "| 1590 | 180      | 60       | 826.2303 | \n",
       "| 1591 | 180      | 61       | 820.0856 | \n",
       "| 1592 | 180      | 62       | 792.1916 | \n",
       "| 1593 | 180      | 63       | 789.5333 | \n",
       "| 1594 | 180      | 64       | 802.3494 | \n",
       "| 1595 | 180      | 65       | 760.4543 | \n",
       "| 1596 | 180      | 66       | 780.5930 | \n",
       "| 1597 | 180      | 67       | 792.8144 | \n",
       "| 1598 | 180      | 68       | 760.7032 | \n",
       "| 1599 | 180      | 69       | 767.3441 | \n",
       "| 1600 | 180      | 70       | 784.9863 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     L   index test    \n",
       "1500 170 140   873.3036\n",
       "1501 170 141   900.3430\n",
       "1502 170 142   769.4254\n",
       "1503 170 143   788.6857\n",
       "1504 170 144   806.9222\n",
       "1505 170 145   753.7217\n",
       "1506 170 146   817.1295\n",
       "1507 170 147   735.1616\n",
       "1508 170 148   865.3539\n",
       "1509 170 149   819.5086\n",
       "1510 170 150   798.2229\n",
       "1511 170 151   776.8275\n",
       "1512 170 152   818.1743\n",
       "1513 170 153   784.9936\n",
       "1514 170 154   862.6428\n",
       "1515 170 155   828.4469\n",
       "1516 170 156   830.3460\n",
       "1517 170 157   728.4254\n",
       "1518 170 158   863.3263\n",
       "1519 170 159   853.2715\n",
       "1520 170 160   819.8846\n",
       "1521 170 161   915.3225\n",
       "1522 170 162   779.2412\n",
       "1523 170 163   747.8102\n",
       "1524 170 164   900.5734\n",
       "1525 170 165   817.9562\n",
       "1526 170 166   851.3701\n",
       "1527 170 167   771.8213\n",
       "1528 170 168   768.3620\n",
       "1529 170 169   783.4469\n",
       "...  ... ...   ...     \n",
       "1571 180 41    801.7464\n",
       "1572 180 42    827.3688\n",
       "1573 180 43    905.2295\n",
       "1574 180 44    725.0322\n",
       "1575 180 45    777.7240\n",
       "1576 180 46    826.0509\n",
       "1577 180 47    806.9876\n",
       "1578 180 48    762.1261\n",
       "1579 180 49    870.1524\n",
       "1580 180 50    799.5588\n",
       "1581 180 51    795.7737\n",
       "1582 180 52    843.1882\n",
       "1583 180 53    859.9428\n",
       "1584 180 54    832.8972\n",
       "1585 180 55    783.4779\n",
       "1586 180 56    805.0465\n",
       "1587 180 57    821.0813\n",
       "1588 180 58    752.0632\n",
       "1589 180 59    756.6053\n",
       "1590 180 60    826.2303\n",
       "1591 180 61    820.0856\n",
       "1592 180 62    792.1916\n",
       "1593 180 63    789.5333\n",
       "1594 180 64    802.3494\n",
       "1595 180 65    760.4543\n",
       "1596 180 66    780.5930\n",
       "1597 180 67    792.8144\n",
       "1598 180 68    760.7032\n",
       "1599 180 69    767.3441\n",
       "1600 180 70    784.9863"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# explore the result of bootstrapping\n",
    "head(times.miss, 100)\n",
    "nrow(times.miss)\n",
    "\n",
    "# check the values of the test errors\n",
    "times.miss[1500:1600,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAOVBMVEUAAAAzMzNNTU1oaGh8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\nETQWKAAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the resulting errors per number of bootstraps\n",
    "times.miss.m <- melt(times.miss, id=c('L')) # reshape for visualization\n",
    "names(times.miss.m) <- c('L', 'type', 'error')\n",
    "ggplot(data=times.miss.m[times.miss.m$type=='test',], aes(factor(L), error,fill=type)) + geom_boxplot(outlier.shape = NA)  + \n",
    "    scale_color_discrete(guide = guide_legend(title = NULL)) + \n",
    "    ggtitle('Error (RMSE) vs. Number of Datasets (Times) (Box Plot)') + theme_minimal()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3-5**\n",
    "\n",
    "\n",
    "Q3-5) Based on your plot in the previous sub-question, Q3-4, how does the test error and its uncertainty behave as the number of subsets in bootstrapping increases? \n",
    "\n",
    "**Answer**\n",
    "\n",
    "As the number of bootstraps increase, **the errors tend to be stable and not deviate too much from each other.** Since bootstrapping is a way to quantify the uncertainty, it shows that as the number of bootstraps become larger the likelihood of getting the average error of the model becomes more apparent. The value of the probability of getting the data given the model $P(D\\mid Model)$ becomes more apparent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C. Probabilistic Machine Learning\n",
    "In this part, you show your knowledge about the foundation of the probabilistic machine learning (i.e. probabilistic inference and modeling) by solving two simple but basic statistical inference problems. Solve the following problems based on the probability concepts you have learned in Module 1 with the same math conventions. Please show your work in your report. Also, there are two conceptual questions.\n",
    "\n",
    "#### Question 4 [Bayes Rule, 20 Marks] \n",
    "Recall the simple example from Appendix A of Module 1. Suppose we have one red and one blue box. In the red box we have 2 apples and 6 oranges, whilst in the blue box we have 3 apples and 1 orange. Now suppose we randomly selected one of the boxes and picked a fruit. If the picked fruit is an apple, what is the probability that it was picked from the blue box?\n",
    "\n",
    "Note that the chance of picking the red box is 40% and the selection chance for any of the pieces from a box is equal for all the pieces in that box.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$\\text{Recall Baye's Theorem:} \\\\$\n",
    "$$\n",
    "P(A\\mid B) = \\frac{P(B\\mid A)P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "\n",
    "$\n",
    "\\text{Let:}\\\\ \\\\\n",
    "P(B=red) - \\text{probability that it was picked from the red box} \\\\\n",
    "P(B=blue) - \\text{probability that it was picked from the blue box} \\\\\n",
    "P(F=apple) - \\text{probability that the fruit picked was an apple} \\\\\n",
    "P(F=orange) - \\text{probability that the fruit picked was an orange} \\\\\n",
    "$\n",
    "\n",
    "$\n",
    "P(B=red) = 0.4\\\\\n",
    "P(B=blue) = 0.6 \\\\\n",
    "P(F=apple\\mid B=blue) = 0.75 \\\\\n",
    "P(F=orange\\mid B=blue) = 0.25 \\\\\n",
    "P(F=apple\\mid B=red) = 0.25 \\\\\n",
    "P(F=orange\\mid B=red) = 0.75\n",
    "$\n",
    "\n",
    "$\n",
    "P(B=blue\\mid F=apple) = \\frac{P(F=apple\\mid B=blue)P(B=blue)}{P(F=apple)} \\\\\n",
    "$\n",
    "\n",
    "$\n",
    "P(B=blue\\mid F=apple) = \\frac{P(F=apple\\mid B=blue)P(B=blue)}{P(F=apple\\mid B=blue)P(B=blue) + P(F=apple\\mid B=blue)P(B=red)} \\\\\n",
    "$\n",
    "\n",
    "$\n",
    "P(B=blue\\mid F=apple) = \\frac{(0.75)(0.6)}{(0.75)(0.6) + (0.25)(0.4)}\n",
    "$\n",
    "\n",
    "$\n",
    "P(B=blue\\mid F=apple) = 0.8182\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5 [Maximum Likelihood, 20 Marks] \n",
    "As opposed to a coin which has two faces, a dice has 6 faces. Suppose we are given a dataset which contains the outcomes of 10 independent tosses of a dice: D:={1,4,5,3,1,2,6,5,6,6}. We are asked to build a model for this dice, i.e. a model which tells what is the probability of each face of the dice if we toss it. Using the maximum likelihood principle, please determine the best value for our model parameters.\n",
    "\n",
    "Hint: You can use a multinomial distribution with 6 probability parameters, each of which corresponding to a dice face (as opposed to coin where there are two parameters). You need to form the likelihood objective function, and then maximise it by setting the derivative with respect to the parameters to zero. Since the probabilities must sum up to 1, you only need to maximise the likelihood objective with respect to five parameters; the value of the sixth parameter is then going to be one minus the sum of the other parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$\\text{Let:} \\\\\n",
    "X = \\{1,2,3,4,5,6\\} \\ \\ \\ \\text{Domain of the random variable X} \\\\\n",
    "D = \\{1,4,5,3,1,2,6,5,6,6\\} \\ \\ \\  \\text{Observed data} \\\\\n",
    "\\newcommand{\\Lagr}{\\mathcal{L}}\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{Let the following be the parameters:}\\\\\n",
    "a = \\text{probability of getting a 1} \\\\\n",
    "b = \\text{probability of getting a 2} \\\\\n",
    "c = \\text{probability of getting a 3} \\\\\n",
    "d = \\text{probability of getting a 4} \\\\\n",
    "e = \\text{probability of getting a 5} \\\\\n",
    "1-a-b-c-d-e = \\text{probability of getting a 6} \\\\\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{Therefore,} \\\\\n",
    "P(X=1) = a \\\\\n",
    "P(X=2) = b \\\\\n",
    "P(X=3) = c \\\\\n",
    "P(X=4) = d \\\\\n",
    "P(X=5) = e \\\\\n",
    "P(X=6) = 1-a-b-c-d-e \\\\\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{We are interested in finding,}\\\\\n",
    "P(D\\mid dice\\ model) = \\prod\\limits_{i=1}^{10} p(x_i\\mid die\\ model) = a^2bcde^2(1-a-b-c-d-e)^3 \\\\\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{Doing Maximum Likelihood Estimation,}\\\\\n",
    "\\frac{\\partial \\Lagr }{\\partial a} = 0, \\frac{\\partial \\Lagr }{\\partial b} = 0, \\frac{\\partial \\Lagr }{\\partial c} = 0, \\frac{\\partial \\Lagr }{\\partial d} = 0, \\frac{\\partial \\Lagr }{\\partial e} = 0\\\\\n",
    "\\begin{align}\\\\\n",
    "\\frac{\\partial \\Lagr }{\\partial a} = \\frac{\\partial[2\\log a+3\\log(1-a-b-c-d-e)]}{\\partial a} = 0 \\\\ \\\\\n",
    "\\frac{\\partial \\Lagr }{\\partial b} = \\frac{\\partial[\\log b+3\\log(1-a-b-c-d-e)]}{\\partial b} = 0 \\\\ \\\\\n",
    "\\frac{\\partial \\Lagr }{\\partial c} = \\frac{\\partial[\\log c+3\\log(1-a-b-c-d-e)]}{\\partial c} = 0 \\\\ \\\\\n",
    "\\frac{\\partial \\Lagr }{\\partial d} = \\frac{\\partial[\\log d+3\\log(1-a-b-c-d-e)]}{\\partial d} = 0 \\\\ \\\\ \n",
    "\\frac{\\partial \\Lagr }{\\partial e} = \\frac{\\partial[2\\log e+3\\log(1-a-b-c-d-e)]}{\\partial e} = 0 \\\\ \\\\\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\frac{2}{a}-\\frac{3}{1-a-b-c-d-e} = 0 \\\\\n",
    "\\frac{1}{b}-\\frac{3}{1-a-b-c-d-e} = 0 \\\\\n",
    "\\frac{1}{c}-\\frac{3}{1-a-b-c-d-e} = 0 \\\\\n",
    "\\frac{1}{d}-\\frac{3}{1-a-b-c-d-e} = 0 \\\\\n",
    "\\frac{2}{e}-\\frac{3}{1-a-b-c-d-e} = 0 \\\\\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "\n",
    "$\n",
    "\\\\\n",
    "\\text{Therefore,} \\\\\n",
    "\\begin{align}\n",
    "\\frac{2}{a} = \\frac{1}{b} = \\frac{1}{c} = \\frac{1}{d} = \\frac{2}{e} = \\frac{3}{1-a-b-c-d-e}\\\\\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{In terms of }a\\text{,}\\\\\n",
    "b = \\frac{a}{2},\\ c = \\frac{a}{2},\\ d = \\frac{a}{2},\\ e = a \\\\\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{Solving for }a\\text{:}\\\\\n",
    "\\begin{align}\n",
    "\\frac{2}{a} = \\frac{3}{1-a-\\frac{a}{2}-\\frac{a}{2}-\\frac{a}{2}-a}\\\\\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\frac{2}{a} = \\frac{3}{1-2a-\\frac{3a}{2}}\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "$\n",
    "2(1-2a-\\frac{3a}{2}) = 3a\\\\\n",
    "2-4a-3a = 3a\\\\\n",
    "2 = 10a\\\\\n",
    "a = \\frac{2}{10}\\\\\n",
    "b = \\frac{1}{10}\\\\\n",
    "c = \\frac{1}{10}\\\\\n",
    "d = \\frac{1}{10}\\\\\n",
    "e = \\frac{2}{10}\n",
    "\\\\\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{Final Answer:}\\\\\n",
    "P(X=1) = a = \\frac{2}{10}\\\\\n",
    "P(X=2) = b = \\frac{1}{10}\\\\\n",
    "P(X=3) = c = \\frac{1}{10}\\\\\n",
    "P(X=4) = d = \\frac{1}{10}\\\\\n",
    "P(X=5) = e = \\frac{2}{10}\\\\\n",
    "P(X=6) = 1-a-b-c-d-e = \\frac{3}{10}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 6: \n",
    "As you have seen through the module, you are generally in the position of choosing a less flexible or more flexible model for your regression or classification problem. You need to be aware that we choose a model to serve to our final goal regardless of the flexibility level. It means that we may prefer a less flexible model to a more flexible model, or vice versa. What are the advantages and disadvantages of a very flexible (versus a less flexible) approach for regression or classification? Under what circumstances might a more flexible approach be preferred to a less flexible approach? When might a less flexible approach be preferred?\n",
    "\n",
    "**Answer**\n",
    "\n",
    "Advantages of a very flexible model:\n",
    "- Tends to have low bias\n",
    "- Reduces the risk of overfitting\n",
    "- Good for large sample sizes even if there are few input variables\n",
    "\n",
    "Disadvantages of a very flexible model:\n",
    "- Might result to greater variance of errors because it's more lenient to noise\n",
    "- Might result to underfitting if the sample size is small\n",
    "\n",
    "A __more flexible model__ is preferred when the <u>sample size is large and the variance of the errors is small.</u>This is because a large sample size makes it closer to the properties of the population, so generalisation (that translates to flexibility) is adequate.\n",
    "\n",
    "A __less flexible model__ is preffered if the <u>sample size is small and the variance of the errors is large</u>. Since we cannot rely on the sample to accurately describe the population we tend to focus more on constraining the parameters to make sure that the noise produced by the model is minimal.\n",
    "\n",
    "#### Question 7: \n",
    "Describe the differences between a parametric and a non-parametric statistical learning approach. What are the advantages of a parametric approach to regression or classification (as opposed to a non- parametric approach)? What are its disadvantages?\n",
    "\n",
    "**Answer**\n",
    "\n",
    "A **parametric** statistical learning approach has a well defined number of parameters that it uses to create a model. The primary goal of training in this case is to determine the coefficient of these parameters to derive the regression or classification function. \n",
    "\n",
    "In contrast, a **non-parametric** statistical learning approach does not rely on a fixed number of parameters in order to create a model from the data. \n",
    "\n",
    "*Advantages and Disadvantages:*\n",
    "\n",
    "**Parametric** approach is generally considered to be simpler to create and faster to execute, although it relies heavily on assumptions, thus putting constraints on the model created. **Non-parametric** approach on the other hand tends to be more complex and takes a longer time to execute, although it provides more flexibility and does not rely on any assumptions in producing the model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
